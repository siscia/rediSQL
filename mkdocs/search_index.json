{
    "docs": [
        {
            "location": "/",
            "text": "RediSQL\n\n\nRediSQL\n is a Redis module that embeds a fully functional SQLite database.\n\n\nAt the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.\n\n\nMoreover, for small, not critical services, it can also be used as main database, it can store data not only in memory but also on file and it can also use the same persistency mechanisms of redis itself.\n\n\nMotivation\n\n\nThe main motivation behind the project is to provide a quick and hands-off environment to store structured data.\n\n\nIt also turns out that RediSQL is a great way to cache your content and data in a more structured way.\n\n\nAnyway, the main history and motivation of the project are explained \nin this page.\n\n\nSustainable Open Source\n\n\nThe project is based on the idea of sustainable Open Source.\n\n\nThe project provides two versions, an open source one, which is enough for most simple projects, and a PRO version that provides features required from companies and enterprises.\n\n\nOverview\n\n\nIn this section, we are going to explore the main concepts in the module.\n\n\nThere is another section of the website, \nthe reference\n, that explore every single command that the module provides giving a deeper explanation of every detail.\n\n\nDatabases\n\n\nRediSQL provides the concept of database.\n\n\nIt is possible to create a new database with the command \nREDISQL.CREATE_DB\n.\n\n\nThe database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.\n\n\nAlso, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.\n\n\nExec\n\n\nREDISQL.EXEC\n is the command that let you execute command against a SQL database.\n\n\nIt is useful when you are testing the module or when you are changing the settings of the databases through SQLite \nPRAGMA\ns.\n\n\nHowever, I would not suggest to use them in production since there are better tools like \nStatements\n.\n\n\nStatements\n\n\nQueries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.\n\n\nWhen you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about \ninserts\n), it can be avoided.\n\n\nWhen you use \nREDISQL.CREATE_STATEMENT\n your statement is compiled, then when you execute it using \nREDISQL.EXEC_STATEMENT\n it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.\n\n\nStatements can also be used as an interface for different application using the same RediSQL instance.\n\n\nOnce you define the interface of the statement and its behavior, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.\n\n\nPersistency\n\n\nThe module in the community version implements only RDB. However, the PRO version provides also AOF and replication.\n\n\nRDB\n\n\nThe module implements RDB persistency.\n\n\nWhen Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.\n\n\nAOF\n\n\nAOF replication is provided only in the PRO edition.\n\n\nAt the moment all the commands are replicated, this is quite a waste and we are moving to replicate only the commands that actually modify the codebase.\n\n\nWith AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances.",
            "title": "Overview"
        },
        {
            "location": "/#redisql",
            "text": "RediSQL  is a Redis module that embeds a fully functional SQLite database.  At the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.  Moreover, for small, not critical services, it can also be used as main database, it can store data not only in memory but also on file and it can also use the same persistency mechanisms of redis itself.",
            "title": "RediSQL"
        },
        {
            "location": "/#motivation",
            "text": "The main motivation behind the project is to provide a quick and hands-off environment to store structured data.  It also turns out that RediSQL is a great way to cache your content and data in a more structured way.  Anyway, the main history and motivation of the project are explained  in this page.",
            "title": "Motivation"
        },
        {
            "location": "/#sustainable-open-source",
            "text": "The project is based on the idea of sustainable Open Source.  The project provides two versions, an open source one, which is enough for most simple projects, and a PRO version that provides features required from companies and enterprises.",
            "title": "Sustainable Open Source"
        },
        {
            "location": "/#overview",
            "text": "In this section, we are going to explore the main concepts in the module.  There is another section of the website,  the reference , that explore every single command that the module provides giving a deeper explanation of every detail.",
            "title": "Overview"
        },
        {
            "location": "/#databases",
            "text": "RediSQL provides the concept of database.  It is possible to create a new database with the command  REDISQL.CREATE_DB .  The database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.  Also, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.",
            "title": "Databases"
        },
        {
            "location": "/#exec",
            "text": "REDISQL.EXEC  is the command that let you execute command against a SQL database.  It is useful when you are testing the module or when you are changing the settings of the databases through SQLite  PRAGMA s.  However, I would not suggest to use them in production since there are better tools like  Statements .",
            "title": "Exec"
        },
        {
            "location": "/#statements",
            "text": "Queries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.  When you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about  inserts ), it can be avoided.  When you use  REDISQL.CREATE_STATEMENT  your statement is compiled, then when you execute it using  REDISQL.EXEC_STATEMENT  it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.  Statements can also be used as an interface for different application using the same RediSQL instance.  Once you define the interface of the statement and its behavior, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.",
            "title": "Statements"
        },
        {
            "location": "/#persistency",
            "text": "The module in the community version implements only RDB. However, the PRO version provides also AOF and replication.",
            "title": "Persistency"
        },
        {
            "location": "/#rdb",
            "text": "The module implements RDB persistency.  When Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.",
            "title": "RDB"
        },
        {
            "location": "/#aof",
            "text": "AOF replication is provided only in the PRO edition.  At the moment all the commands are replicated, this is quite a waste and we are moving to replicate only the commands that actually modify the codebase.  With AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances.",
            "title": "AOF"
        },
        {
            "location": "/references/",
            "text": "References\n\n\nThis document explains all the API that RediSQL provide to the users.\n\n\nFor each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.\n\n\nWhere is possible it provides also an estimate of the complexity since we are talking about databases not all queries have the same time and spatial complexity.\n\n\nFinally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.\n\n\nREDISQL.CREATE_DB\n\n\nREDISQL.CREATE_DB db_key [path]\n\n\nThis command creates a new DB and associates it with the key.\n\n\nThe path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.\n\n\nIf the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.\n\n\nIf the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string \n:memory:\n as path argument.\n\n\nAfter opening the database it inserts metadata into it and then starts a thread loop.\n\n\nComplexity\n: O(1), it means constant, it does not necessarily mean \nfast\n. However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_open_v2\n\n\n\n\nDEL\n\n\nDEL db_key [key ...]\n\n\nThis command is a generic command from Redis.\n\n\nIt eliminates keys from Redis itself, as well if the key is a RediSQL database create with \nREDISQL.CREATE_DB\n it will eliminate the SQLite database, stop the thread loop and clean up everything left.\n\n\nIf the database is backed by a file the file will be close.\n\n\nComplexity\n: DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_close\n\n\nRedis \nDEL\n\n\n\n\nREDISQL.EXEC\n\n\nREDISQL.EXEC db_key \"statement\"\n\n\nThis command takes as input a Redis key created with \nREDISQL.CREATE_DB\n and a statement string.\n\n\nInternally it transform the string into a \nsqlite statement\n using \nsqlite3_prepare_v2\n, execute it against the database, \nsqlite3_step\n, and finally returns the results to the client.\n\n\nThe compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.\n\n\nThis command is quite useful to execute \nPRAGMA Statements\n, for normal operations against the database is suggested to use \nSTATEMENTS\n.\n\n\nAlso, remember that there is only a single thread for database, execution of multiple \nREDISQL.EXEC\n against the same database will result in a serialization of the executions, one will be executed before the others.\n\n\nComplexity\n: It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.CREATE_STATEMENT db_key stmt_identifier \"statement\"\n\n\nThis command compiles a statement string into a \nsqlite statement\n and associate such statement to an identifier.\n\n\nUsing this command you can insert parameters using the special symbol \n?NNN\n, those parameters will be bind to the statements when you are executing the statement itself.\n\n\nFor now only the \n?NNN\n syntax is supported, where \nN\n is a digit (Ex. \n?1\n, \n?2\n, \n?3\n ...)\n\n\nThis command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided (\nstmt_identifier\n). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.\n\n\nThe statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.\n\n\nYou can execute the statement with \nREDISQL.EXEC_STATEMENT\n.\n\n\nYou cannot overwrite a statement using this command.\n\n\nIf you need to change the implementation of a statement you have two options:\n\n\n\n\nDelete the statement using \nREDISQL.DELETE_STATEMENT\n and the create a new one.\n\n\nUse \nREDISQL.UPDATE_STATEMENT\n\n\n\n\nSuppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.\n\n\nAlso, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.\n\n\nPlease keep in mind that the parameters should be named in order and that there should not be any gap.\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it\n\n\n\n\nKeep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using \n?0\n is an error.\n\n\nComplexity\n: If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily \nfast\n.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT db_key stmt_identifier [binding_parameters ...]\n\n\nThis command binds all the parameters to the statement created using \nREDISQL.CREATE_STATEMENT\n and identified by \nstmt_identifier\n. Then the module executes the statement against the database associated to \ndb_key\n.\n\n\nFor each parameter in the query of the form \n?nnn\n the engine will look for the \nnnn-th\n binding_parameters.\nSo if the statements is from the following query:\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3);\n\n\n\n\nYou will only need to provide 3 parameters and they will be bound, in order to \n?1\n, \n?2\n and \n?3\n.\n\n\nIf your statements looks like this:\n\n\nINSERT INTO foo VALUES(?1, ?123, ?564);\n\n\n\n\nYou will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.\n\n\nSQLite starts to count the binding parameters from 0, not from 1. Using \n?0\n is an error.\n\n\nRedis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure \nsqlite3_bind_text\n, however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.\n\n\nFinally, once completed the binding part the statement is executed and its result is returned to the client.\n\n\nThis command as well is not blocking, all the work happens in a different thread from the one of Redis.\n\n\nComplexity\n: The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.CREATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT db_key stmt_identifier\n\n\nThis command eliminates a statement from the database.\n\n\nIt first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.\n\n\nAlso, this command is not blocking and work in a different thread from the main Redis one.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT db_key stmt_identifier \"statement\"\n\n\nThe command update and \nexisting\n statement changing its internal implementation to the one provide as string.\n\n\nIf the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.\n\n\nInternally the command starts checking if the statement is already defined, then it tries to compile the string into a \nsqlite3_stmt\n and if everything went right it finally updates the metadata table and finally returns to the client.\n\n\nThis command is not blocking as well.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nRedis Blocking Command",
            "title": "References"
        },
        {
            "location": "/references/#references",
            "text": "This document explains all the API that RediSQL provide to the users.  For each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.  Where is possible it provides also an estimate of the complexity since we are talking about databases not all queries have the same time and spatial complexity.  Finally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.",
            "title": "References"
        },
        {
            "location": "/references/#redisqlcreate_db",
            "text": "REDISQL.CREATE_DB db_key [path]  This command creates a new DB and associates it with the key.  The path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.  If the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.  If the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string  :memory:  as path argument.  After opening the database it inserts metadata into it and then starts a thread loop.  Complexity : O(1), it means constant, it does not necessarily mean  fast . However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)  See also :    SQLite  sqlite3_open_v2",
            "title": "REDISQL.CREATE_DB"
        },
        {
            "location": "/references/#del",
            "text": "DEL db_key [key ...]  This command is a generic command from Redis.  It eliminates keys from Redis itself, as well if the key is a RediSQL database create with  REDISQL.CREATE_DB  it will eliminate the SQLite database, stop the thread loop and clean up everything left.  If the database is backed by a file the file will be close.  Complexity : DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).  See also :    SQLite  sqlite3_close  Redis  DEL",
            "title": "DEL"
        },
        {
            "location": "/references/#redisqlexec",
            "text": "REDISQL.EXEC db_key \"statement\"  This command takes as input a Redis key created with  REDISQL.CREATE_DB  and a statement string.  Internally it transform the string into a  sqlite statement  using  sqlite3_prepare_v2 , execute it against the database,  sqlite3_step , and finally returns the results to the client.  The compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.  This command is quite useful to execute  PRAGMA Statements , for normal operations against the database is suggested to use  STATEMENTS .  Also, remember that there is only a single thread for database, execution of multiple  REDISQL.EXEC  against the same database will result in a serialization of the executions, one will be executed before the others.  Complexity : It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command",
            "title": "REDISQL.EXEC"
        },
        {
            "location": "/references/#redisqlcreate_statement",
            "text": "REDISQL.CREATE_STATEMENT db_key stmt_identifier \"statement\"  This command compiles a statement string into a  sqlite statement  and associate such statement to an identifier.  Using this command you can insert parameters using the special symbol  ?NNN , those parameters will be bind to the statements when you are executing the statement itself.  For now only the  ?NNN  syntax is supported, where  N  is a digit (Ex.  ?1 ,  ?2 ,  ?3  ...)  This command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided ( stmt_identifier ). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.  The statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.  You can execute the statement with  REDISQL.EXEC_STATEMENT .  You cannot overwrite a statement using this command.  If you need to change the implementation of a statement you have two options:   Delete the statement using  REDISQL.DELETE_STATEMENT  and the create a new one.  Use  REDISQL.UPDATE_STATEMENT   Suppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.  Also, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.  Please keep in mind that the parameters should be named in order and that there should not be any gap.  INSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it  Keep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using  ?0  is an error.  Complexity : If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily  fast .  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.CREATE_STATEMENT"
        },
        {
            "location": "/references/#redisqlexec_statement",
            "text": "REDISQL.EXEC_STATEMENT db_key stmt_identifier [binding_parameters ...]  This command binds all the parameters to the statement created using  REDISQL.CREATE_STATEMENT  and identified by  stmt_identifier . Then the module executes the statement against the database associated to  db_key .  For each parameter in the query of the form  ?nnn  the engine will look for the  nnn-th  binding_parameters.\nSo if the statements is from the following query:  INSERT INTO foo VALUES(?1, ?2, ?3);  You will only need to provide 3 parameters and they will be bound, in order to  ?1 ,  ?2  and  ?3 .  If your statements looks like this:  INSERT INTO foo VALUES(?1, ?123, ?564);  You will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.  SQLite starts to count the binding parameters from 0, not from 1. Using  ?0  is an error.  Redis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure  sqlite3_bind_text , however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.  Finally, once completed the binding part the statement is executed and its result is returned to the client.  This command as well is not blocking, all the work happens in a different thread from the one of Redis.  Complexity : The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.  See also :   SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.CREATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.EXEC_STATEMENT"
        },
        {
            "location": "/references/#redisqldelete_statement",
            "text": "REDISQL.DELETE_STATEMENT db_key stmt_identifier  This command eliminates a statement from the database.  It first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.  Also, this command is not blocking and work in a different thread from the main Redis one.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.DELETE_STATEMENT"
        },
        {
            "location": "/references/#redisqlupdate_statement",
            "text": "REDISQL.UPDATE_STATEMENT db_key stmt_identifier \"statement\"  The command update and  existing  statement changing its internal implementation to the one provide as string.  If the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.  Internally the command starts checking if the statement is already defined, then it tries to compile the string into a  sqlite3_stmt  and if everything went right it finally updates the metadata table and finally returns to the client.  This command is not blocking as well.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.UPDATE_STATEMENT"
        },
        {
            "location": "/motivations/",
            "text": "Motivation\n\n\nThis document explains the motivations behind this redis module.\n\n\nMy personal use case\n\n\nAs a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.\n\n\nI was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.\n\n\nRedis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.\n\n\nHowever, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.\n\n\nAt that time I had only the following options:\n\n\n\n\nKeep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.\n\n\nBring in another piece inside my architecture, namely an SQL database.\n\n\n\n\nFor some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.\n\n\nOperating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.\n\n\nAlso, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.\n\n\nMy project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.\n\n\nWhy RediSQL\n\n\nThe goal of the module is to create a third alternative to the two mentioned above.\n\n\nI wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.\n\n\nSQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.\n\n\nFinally, merging the two project was just made possible by the introduction of the Redis modules.\n\n\nHence, RediSQL was born.\n\n\nPossible uses\n\n\nRediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.\n\n\nHowever, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.\n\n\nMoreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.\n\n\nThis makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Motivations"
        },
        {
            "location": "/motivations/#motivation",
            "text": "This document explains the motivations behind this redis module.",
            "title": "Motivation"
        },
        {
            "location": "/motivations/#my-personal-use-case",
            "text": "As a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.  I was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.  Redis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.  However, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.  At that time I had only the following options:   Keep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.  Bring in another piece inside my architecture, namely an SQL database.   For some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.  Operating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.  Also, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.  My project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.",
            "title": "My personal use case"
        },
        {
            "location": "/motivations/#why-redisql",
            "text": "The goal of the module is to create a third alternative to the two mentioned above.  I wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.  SQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.  Finally, merging the two project was just made possible by the introduction of the Redis modules.  Hence, RediSQL was born.",
            "title": "Why RediSQL"
        },
        {
            "location": "/motivations/#possible-uses",
            "text": "RediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.  However, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.  Moreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.  This makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Possible uses"
        },
        {
            "location": "/blog/analytics/",
            "text": "RediSQL for analytics\n\n\nRediSQL is a module for Redis that embed a completely functional SQLite database. \n\n\nRediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.\n\n\nIn this blog post, we are going to explore how RediSQL can be used for storing analytics data.\n\n\nRedis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.\n\n\nWe are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.\n\n\nAt the end of the article, there is actual python code that you can run.\n\n\nProblem\n\n\nSuppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.\n\n\nAll these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.\n\n\nHowever, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.\n\n\nData Structure\n\n\nOne of the advantages of using SQL is the possibility to use and declare the shape of your data.\n\n\nFor this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.\n\n\nWe are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.\n\n\nEvents\n\n\nRepresenting the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.\n\n\nHowever you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.\n\n\nJSON or Tables\n\n\nIf your events are quite static and you already know what you are going to store the best approach is to use tables.\n\n\nAn idea could be to use this representation for the table \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|\n\n\n\n\nAnd then different tables for each type of events, like:\n\n\nSales\n:\n\n\n| event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|\n\n\n\n\nSubmits\n:\n\n\n| event_id | url_page | A/B_version |\n|----------|----------|-------------|\n\n\n\n\nWhere \nevent_id\n is a Primary key to the table \nEvents\n and a Foreign key on the table \nSales\n and \nSubmits\n.\n\n\nThis approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.\n\n\nA different approach will be to store directly JSON in your table.\n\n\nThe new schema will be only a single table, \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|\n\n\n\n\nThe column data will be of type \ntext\n and it will store anything you want if encoded in JSON.\n\n\nOf course, it is also possible to run any kind of computation on the JSON data including filters and selection.\n\n\nUsing JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.\n\n\nSolution Sketch\n\n\nIn this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.\n\n\nI am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out \nthe readme of the project\n\n\nWe are going to automate as much as possible in this tutorial, in this way your analytic script will just run.\n\n\nThe very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.\n\n\nimport redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n\n\n\nNow that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy, \nDB\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"\n\n\n\n\nNow that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.\n\n\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]\n\n\n\n\nSetting the type of \nevent_id\n as \nINTEGER PRIMARY KEY\n is synonymous with \nROWID\n which is an autoincrement fields that do not need to be set during insert.\n\n\nAt this point, the only thing left to do is to listen for events in your code and write them into the database.\n\n\nThe simplest, and insecure, way to write the data is to use the \nEXEC\n function like so:\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]\n\n\n\n\nAs you may have guessed already the return value of \nREDISQL.EXEC\n is a list of two elements, the string \nDONE\n and the integer representing the number of rows modified (inserted, deleted or updated).\n\n\nHowever, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.\n\n\nThe better and safer way to do this kind of operation is to define \nstatements\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"\n\n\n\n\nOnce a statement is defined you can execute it using the following commands.\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]\n\n\n\n\nThe use of statements brings some benefits.\n\n\n\n\nIt reduces code deduplication in your code base\n\n\nIt puts a name on a particular procedure, decoupling the implementation and the goal\n\n\nIt allows different microservices to invoke the always the exact same procedure\n\n\nIt is faster to execute\n\n\n\n\nUse the JSON1 SQLite module\n\n\nNow that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.\n\n\nThe ones that follow are plain SQL statements that you can execute \nREDISQL.EXEC\n against the database or that you can embed into a statement.\n\n\nThe most interesting function provide is \njson_extract\n.\n\n\nSELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";\n\n\n\n\nThis query will look inside the field \ntype\n of the JSON stored into the columns \ndata\n if this fields contains the string \"sales\" it will return the user who bought something and total of the sale. \n\n\njson_extract\n works also on array using a simple syntax: \n$.array[2]\n (eg. extract the third element of the array)\n\n\nMove the data\n\n\nRunning the above script will be extremely fast, I am talking about 10ks inserts per second fast.\n\n\nHowever, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.\n\n\nThis can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.\n\n\nThe simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.\n\n\nA quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.\n\n\nThis operation is quite simple and it can be done like so.\n\n\n# get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)\n\n\n\n\nNow you can use tools like PostgreSQL COPY to load all the data into your database.\n\n\nThis solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.\n\n\nRecap\n\n\nIn this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.\n\n\nAdding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.\n\n\nIs worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Analytics"
        },
        {
            "location": "/blog/analytics/#redisql-for-analytics",
            "text": "RediSQL is a module for Redis that embed a completely functional SQLite database.   RediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.  In this blog post, we are going to explore how RediSQL can be used for storing analytics data.  Redis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.  We are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.  At the end of the article, there is actual python code that you can run.",
            "title": "RediSQL for analytics"
        },
        {
            "location": "/blog/analytics/#problem",
            "text": "Suppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.  All these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.  However, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.",
            "title": "Problem"
        },
        {
            "location": "/blog/analytics/#data-structure",
            "text": "One of the advantages of using SQL is the possibility to use and declare the shape of your data.  For this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.  We are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.  Events  Representing the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.  However you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.  JSON or Tables  If your events are quite static and you already know what you are going to store the best approach is to use tables.  An idea could be to use this representation for the table  Events :  | event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|  And then different tables for each type of events, like:  Sales :  | event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|  Submits :  | event_id | url_page | A/B_version |\n|----------|----------|-------------|  Where  event_id  is a Primary key to the table  Events  and a Foreign key on the table  Sales  and  Submits .  This approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.  A different approach will be to store directly JSON in your table.  The new schema will be only a single table,  Events :  | event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|  The column data will be of type  text  and it will store anything you want if encoded in JSON.  Of course, it is also possible to run any kind of computation on the JSON data including filters and selection.  Using JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.",
            "title": "Data Structure"
        },
        {
            "location": "/blog/analytics/#solution-sketch",
            "text": "In this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.  I am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out  the readme of the project  We are going to automate as much as possible in this tutorial, in this way your analytic script will just run.  The very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.  import redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)  Now that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy,  DB .  ok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"  Now that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.  done = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]  Setting the type of  event_id  as  INTEGER PRIMARY KEY  is synonymous with  ROWID  which is an autoincrement fields that do not need to be set during insert.  At this point, the only thing left to do is to listen for events in your code and write them into the database.  The simplest, and insecure, way to write the data is to use the  EXEC  function like so:  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]  As you may have guessed already the return value of  REDISQL.EXEC  is a list of two elements, the string  DONE  and the integer representing the number of rows modified (inserted, deleted or updated).  However, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.  The better and safer way to do this kind of operation is to define  statements .  ok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"  Once a statement is defined you can execute it using the following commands.  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]  The use of statements brings some benefits.   It reduces code deduplication in your code base  It puts a name on a particular procedure, decoupling the implementation and the goal  It allows different microservices to invoke the always the exact same procedure  It is faster to execute   Use the JSON1 SQLite module  Now that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.  The ones that follow are plain SQL statements that you can execute  REDISQL.EXEC  against the database or that you can embed into a statement.  The most interesting function provide is  json_extract .  SELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";  This query will look inside the field  type  of the JSON stored into the columns  data  if this fields contains the string \"sales\" it will return the user who bought something and total of the sale.   json_extract  works also on array using a simple syntax:  $.array[2]  (eg. extract the third element of the array)",
            "title": "Solution Sketch"
        },
        {
            "location": "/blog/analytics/#move-the-data",
            "text": "Running the above script will be extremely fast, I am talking about 10ks inserts per second fast.  However, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.  This can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.  The simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.  A quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.  This operation is quite simple and it can be done like so.  # get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)  Now you can use tools like PostgreSQL COPY to load all the data into your database.  This solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.",
            "title": "Move the data"
        },
        {
            "location": "/blog/analytics/#recap",
            "text": "In this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.  Adding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.  Is worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Recap"
        }
    ]
}