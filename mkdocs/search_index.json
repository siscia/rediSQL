{
    "docs": [
        {
            "location": "/",
            "text": "RediSQL\n\n\nRediSQL\n is a Redis module that embeds a fully functional SQLite database.\n\n\nAt the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as a cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.\n\n\nMoreover, it can also be used as the main database, it can store data not only in memory but also on file and it can also use the same persistence mechanisms of redis itself.\n\n\nGet Started\n\n\nYou can download the module directly \nfrom github releases\n.\n\n\nYou can start the module with:\n\n\n./redis-server --loadmodule rediSQL_<version>.so\n\n\n\n\nAfter starting redis with the rediSQL module it will be just the redis you learn to love:\n\n\n$ ~/redis-4.0-rc1/src/redis-cli \n127.0.0.1:6379> \n127.0.0.1:6379> SET A 3\nOK\n127.0.0.1:6379> GET A\n\"3\"\n\n\n\n\nBut you will also able to use all the API described below:\n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n# Start creating a table on the default DB\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(A INT, B TEXT);\"\nDONE\n# Insert some data into the table\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 'bar');\"\nOK\n# Retrieve the data you just inserted\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo;\"\n1) 1) (integer) 3\n   2) \"bar\"\n# Of course you can make multiple tables\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE baz(C INT, B TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'aaa');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'bbb');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'ccc');\"\nOK\n# And of course you can use joins\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo, baz WHERE foo.A = baz.C;\"\n\n1) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"aaa\"\n2) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"bbb\"\n3) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"ccc\"\n127.0.0.1:6379> \n\n\n\n\nAlso the \nLIKE\n operator is included:\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE text_search(t TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('hello');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('banana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('apple');\"\nOK\n127.0.0.1:6379> \n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'h_llo';\"\n1) 1) \"hello\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE '%anana';\"\n1) 1) \"banana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('anana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search;\"\n1) 1) \"hello\"\n2) 1) \"banana\"\n3) 1) \"apple\"\n4) 1) \"anana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'a%';\"\n1) 1) \"apple\"\n2) 1) \"anana\"\n\n\n\n\nNow you can create tables, insert data on those tables, make queries, remove elements, everything.\n\n\nOverview\n\n\nIn this section, we are going to explore the main concepts in the module.\n\n\nThere is another section of the website, \nthe reference\n, that explore every single command that the module provides giving a deeper explanation of every detail.\n\n\nDatabases\n\n\nRediSQL provides the concept of database.\n\n\nIt is possible to create a new database with the command \nREDISQL.CREATE_DB\n.\n\n\nThe database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.\n\n\nAlso, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.\n\n\nExec\n\n\nREDISQL.EXEC\n is the command that let you execute command against a SQL database.\n\n\nIt is useful when you are testing the module or when you are changing the settings of the databases through SQLite \nPRAGMA\ns.\n\n\nHowever, I would not suggest to use them in production since there are better tools like \nStatements\n.\n\n\nStatements\n\n\nQueries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.\n\n\nWhen you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about \ninserts\n), it can be avoided.\n\n\nWhen you use \nREDISQL.CREATE_STATEMENT\n your statement is compiled, then when you execute it using \nREDISQL.EXEC_STATEMENT\n it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.\n\n\nStatements can also be used as an interface for different applications using the same RediSQL instance.\n\n\nOnce you define the interface of the statement and its behaviour, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.\n\n\nQuery\n\n\nIn most databases there are statements that modify the data and queries that simply read.\n\n\nOf course, just reading, is usually a faster and simpler operation than modify the data. In order to take advantages of this, we provide a different command \nREDISQL.QUERY\n and \nREDISQL.QUERY_STATEMENT\n that constraint you to don't modify the data.\n\n\nThese commands allow you to have slaves/replicas serves query and to balance some load off the master node for better speed and reliability.\n\n\nPersistency\n\n\nThe module in the community version implements only RDB. However, the PRO version provides also AOF and replication.\n\n\nRDB\n\n\nThe module implements RDB persistency.\n\n\nWhen Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.\n\n\nAOF\n\n\nAOF replication is provided only in the PRO edition.\n\n\nAll the commands are replicated, but the read-only ones.\n\n\nWith AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances in a master/slave fashion.\n\n\nObtain\n\n\nThere are \ntwo version\n of the software, a \"community\", completely open source version and a PRO version that comes with \nmore features and support plan.\n\n\nBoth versions can be \nobtained in the store.\n\n\nFor the community version, you can just download it, we ask for a small donation if you can support the project but feel free to just input 0\u20ac and download it.\n\n\nFor the PRO version you need to \nsign up here\n, after you signed up you will be able to download the software.\n\n\nA detailed coverage of the PRO version \nis provided here\n\n\nFinally you can also obtain the software from \ngithub releases\n\n\nMotivation\n\n\nThe main motivation behind the project is to provide a quick and hands-off environment to store structured data.\n\n\nIt also turns out that RediSQL is a great way to cache your content and data in a more structured way.\n\n\nThe main history and motivation of the project are explained \nin this page.\n\n\nPRO\n\n\nThe PRO edition is based on the Open Source one, however, it provides one more class of commands that are necessary for business or where rediSQL is a critical piece of the infrastructure.\n\n\nEvery command, but \nREDISQL.CREATE_DB\n, blocks the clients and it is executed in the background by a different thread.\n\n\nWith the PRO version, we also provide the \n.NOW\n commands that are executed immediately without blocking the client.\n\n\nEvery command in the PRO version provides the \n.NOW\n variant, but please refer to the \nreference\n.\n\n\nMoreover, the PRO version also provides AOF replication, that, indeed, necessitate of commands that don't block the clients.\n\n\nMore information about the PRO version are available \nhere.",
            "title": "Overview"
        },
        {
            "location": "/#redisql",
            "text": "RediSQL  is a Redis module that embeds a fully functional SQLite database.  At the best of our knowledge is the only system that provides SQL capabilities while being very fast so to be used as a cache, simple to integrate with any programming language, since it can be used by every redis client, and with very very low maintenance.  Moreover, it can also be used as the main database, it can store data not only in memory but also on file and it can also use the same persistence mechanisms of redis itself.",
            "title": "RediSQL"
        },
        {
            "location": "/#get-started",
            "text": "You can download the module directly  from github releases .  You can start the module with:  ./redis-server --loadmodule rediSQL_<version>.so  After starting redis with the rediSQL module it will be just the redis you learn to love:  $ ~/redis-4.0-rc1/src/redis-cli \n127.0.0.1:6379> \n127.0.0.1:6379> SET A 3\nOK\n127.0.0.1:6379> GET A\n\"3\"  But you will also able to use all the API described below:  127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n# Start creating a table on the default DB\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE foo(A INT, B TEXT);\"\nDONE\n# Insert some data into the table\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO foo VALUES(3, 'bar');\"\nOK\n# Retrieve the data you just inserted\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo;\"\n1) 1) (integer) 3\n   2) \"bar\"\n# Of course you can make multiple tables\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE baz(C INT, B TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'aaa');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'bbb');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO baz VALUES(3, 'ccc');\"\nOK\n# And of course you can use joins\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM foo, baz WHERE foo.A = baz.C;\"\n\n1) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"aaa\"\n2) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"bbb\"\n3) 1) (integer) 3\n   2) \"bar\"\n   3) (integer) 3\n   4) \"ccc\"\n127.0.0.1:6379>   Also the  LIKE  operator is included:  127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE text_search(t TEXT);\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('hello');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('banana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('apple');\"\nOK\n127.0.0.1:6379> \n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'h_llo';\"\n1) 1) \"hello\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE '%anana';\"\n1) 1) \"banana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"INSERT INTO text_search VALUES('anana');\"\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search;\"\n1) 1) \"hello\"\n2) 1) \"banana\"\n3) 1) \"apple\"\n4) 1) \"anana\"\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM text_search WHERE t LIKE 'a%';\"\n1) 1) \"apple\"\n2) 1) \"anana\"  Now you can create tables, insert data on those tables, make queries, remove elements, everything.",
            "title": "Get Started"
        },
        {
            "location": "/#overview",
            "text": "In this section, we are going to explore the main concepts in the module.  There is another section of the website,  the reference , that explore every single command that the module provides giving a deeper explanation of every detail.",
            "title": "Overview"
        },
        {
            "location": "/#databases",
            "text": "RediSQL provides the concept of database.  It is possible to create a new database with the command  REDISQL.CREATE_DB .  The database is associated with a Redis key and so it is possible to have multiple SQL databases in a single Redis instance.  Also, it is possible to use in-memory database, which is the default, or databases backed by a real file. In-memory databases are generally a little faster but they are limited by the amount of memory your server has. Database backed by files are a little slower but they can grow basically indefinitely.",
            "title": "Databases"
        },
        {
            "location": "/#exec",
            "text": "REDISQL.EXEC  is the command that let you execute command against a SQL database.  It is useful when you are testing the module or when you are changing the settings of the databases through SQLite  PRAGMA s.  However, I would not suggest to use them in production since there are better tools like  Statements .",
            "title": "Exec"
        },
        {
            "location": "/#statements",
            "text": "Queries and statements can be precompiled and stores inside the Redis key in order to provide a faster execution and more agility in your application.  When you execute an SQLite query, the text is compiled to a binary code, this binary code is then executed against the database and the result provide an answer.\nThe phase of compilation can be quite expensive, but if you always execute the same statements (think about  inserts ), it can be avoided.  When you use  REDISQL.CREATE_STATEMENT  your statement is compiled, then when you execute it using  REDISQL.EXEC_STATEMENT  it is not re-compiled but we use the pre-compiled one. It seems a trivial change but it will really speed up some workload.  Statements can also be used as an interface for different applications using the same RediSQL instance.  Once you define the interface of the statement and its behaviour, then you are free to change it's implementation while maintaining all the legacy code working.\nThis is quite useful especially if you have several services using the same RediSQL instance.",
            "title": "Statements"
        },
        {
            "location": "/#query",
            "text": "In most databases there are statements that modify the data and queries that simply read.  Of course, just reading, is usually a faster and simpler operation than modify the data. In order to take advantages of this, we provide a different command  REDISQL.QUERY  and  REDISQL.QUERY_STATEMENT  that constraint you to don't modify the data.  These commands allow you to have slaves/replicas serves query and to balance some load off the master node for better speed and reliability.",
            "title": "Query"
        },
        {
            "location": "/#persistency",
            "text": "The module in the community version implements only RDB. However, the PRO version provides also AOF and replication.",
            "title": "Persistency"
        },
        {
            "location": "/#rdb",
            "text": "The module implements RDB persistency.  When Redis starts to save the RDB file the status of the database get serialized and written, along with all the other information, in the RDB file.",
            "title": "RDB"
        },
        {
            "location": "/#aof",
            "text": "AOF replication is provided only in the PRO edition.  All the commands are replicated, but the read-only ones.  With AOF replication you also get instance replication that allows replicating the same dataset into different Redis instances in a master/slave fashion.",
            "title": "AOF"
        },
        {
            "location": "/#obtain",
            "text": "There are  two version  of the software, a \"community\", completely open source version and a PRO version that comes with  more features and support plan.  Both versions can be  obtained in the store.  For the community version, you can just download it, we ask for a small donation if you can support the project but feel free to just input 0\u20ac and download it.  For the PRO version you need to  sign up here , after you signed up you will be able to download the software.  A detailed coverage of the PRO version  is provided here  Finally you can also obtain the software from  github releases",
            "title": "Obtain"
        },
        {
            "location": "/#motivation",
            "text": "The main motivation behind the project is to provide a quick and hands-off environment to store structured data.  It also turns out that RediSQL is a great way to cache your content and data in a more structured way.  The main history and motivation of the project are explained  in this page.",
            "title": "Motivation"
        },
        {
            "location": "/#pro",
            "text": "The PRO edition is based on the Open Source one, however, it provides one more class of commands that are necessary for business or where rediSQL is a critical piece of the infrastructure.  Every command, but  REDISQL.CREATE_DB , blocks the clients and it is executed in the background by a different thread.  With the PRO version, we also provide the  .NOW  commands that are executed immediately without blocking the client.  Every command in the PRO version provides the  .NOW  variant, but please refer to the  reference .  Moreover, the PRO version also provides AOF replication, that, indeed, necessitate of commands that don't block the clients.  More information about the PRO version are available  here.",
            "title": "PRO"
        },
        {
            "location": "/references/",
            "text": "References\n\n\nThis document explains all the API that RediSQL provide to the users.\n\n\nFor each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.\n\n\nWhere is possible, it provides also an estimate of the complexity but since we are talking about databases not all queries have the same time and spatial complexity.\n\n\nFinally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.\n\n\nREDISQL.CREATE_DB\n\n\nREDISQL.CREATE_DB db_key [path]\n\n\nThis command creates a new DB and associates it with the key.\n\n\nThe path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.\n\n\nIf the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.\n\n\nIf the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string \n:memory:\n as path argument.\n\n\nAfter opening the database it inserts metadata into it and then starts a thread loop.\n\n\nComplexity\n: O(1), it means constant, it does not necessarily mean \nfast\n. However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_open_v2\n\n\n\n\nDEL\n\n\nDEL db_key [key ...]\n\n\nThis command is a generic command from Redis.\n\n\nIt eliminates keys from Redis itself, as well if the key is a RediSQL database create with \nREDISQL.CREATE_DB\n it will eliminate the SQLite database, stop the thread loop and clean up everything left.\n\n\nIf the database is backed by a file the file will be close.\n\n\nComplexity\n: DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).\n\n\nSee also\n: \n\n\n\n\nSQLite \nsqlite3_close\n\n\nRedis \nDEL\n\n\n\n\nREDISQL.EXEC\n\n\nREDISQL.EXEC[.NOW] db_key \"statement\"\n\n\nThis command takes as input a Redis key created with \nREDISQL.CREATE_DB\n and a statement string.\n\n\nInternally it transform the string into a \nsqlite statement\n using \nsqlite3_prepare_v2\n, execute it against the database, \nsqlite3_step\n, and finally returns the results to the client.\n\n\nThe compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.\n\n\nThis command is quite useful to execute \nPRAGMA Statements\n, for normal operations against the database is suggested to use \nSTATEMENTS\n.\n\n\nAlso, remember that there is only a single thread for database, execution of multiple \nREDISQL.EXEC\n against the same database will result in a serialization of the executions, one will be executed before the others.\n\n\nIf you only need to query the database without modifying the data is a better idea to use \nREDISQL.QUERY\n.\n\n\nComplexity\n: It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.QUERY\n\n\nREDISQL.QUERY[.NOW] db_key \"statement\"\n\n\nThis command behaves similarly to \nREDISQL.EXEC\n but it imposes an additional constraint on the statement it executes.\n\n\nIt only executes the statement if it is a read-only operation, otherwise, it returns an error.\n\n\nA read-only operation is defined by the result of calling \nsqlite3_stmt_readonly\n on the compiled statement.\n\n\nThe statement is executed if and only if \nsqlite3_stmt_readonly\n returns true.\n\n\nIf you need to execute the same query over and over it is a good idea to create a statement and use \nREDISQL.QUERY_STATEMENT\n.\n\n\nComplexity\n: Similar to \nREDISQL.EXEC\n, however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n \n\n\nREDISQL.EXEC\n\n\nSQLite \nsqlite3_stmt_readonly\n\n\nREDISQL.QUERY_STATEMENT\n \n\n\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.CREATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"\n\n\nThis command compiles a statement string into a \nsqlite statement\n and associate such statement to an identifier.\n\n\nUsing this command you can insert parameters using the special symbol \n?NNN\n, those parameters will be bind to the statements when you are executing the statement itself.\n\n\nFor now only the \n?NNN\n syntax is supported, where \nN\n is a digit (Ex. \n?1\n, \n?2\n, \n?3\n ...)\n\n\nThis command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided (\nstmt_identifier\n). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.\n\n\nThe statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.\n\n\nYou can execute the statement with \nREDISQL.EXEC_STATEMENT\n.\n\n\nYou cannot overwrite a statement using this command.\n\n\nIf you need to change the implementation of a statement you have two options:\n\n\n\n\nDelete the statement using \nREDISQL.DELETE_STATEMENT\n and the create a new one.\n\n\nUse \nREDISQL.UPDATE_STATEMENT\n\n\n\n\nSuppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.\n\n\nAlso, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.\n\n\nPlease keep in mind that the parameters should be named in order and that there should not be any gap.\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it\n\n\n\n\nKeep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using \n?0\n is an error.\n\n\nComplexity\n: If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily \nfast\n.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]\n\n\nThis command binds all the parameters to the statement created using \nREDISQL.CREATE_STATEMENT\n and identified by \nstmt_identifier\n. Then the module executes the statement against the database associated to \ndb_key\n.\n\n\nFor each parameter in the query of the form \n?nnn\n the engine will look for the \nnnn-th\n binding_parameters.\nSo if the statements is from the following query:\n\n\nINSERT INTO foo VALUES(?1, ?2, ?3);\n\n\n\n\nYou will only need to provide 3 parameters and they will be bound, in order to \n?1\n, \n?2\n and \n?3\n.\n\n\nIf your statements looks like this:\n\n\nINSERT INTO foo VALUES(?1, ?123, ?564);\n\n\n\n\nYou will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.\n\n\nSQLite starts to count the binding parameters from 0, not from 1. Using \n?0\n is an error.\n\n\nRedis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure \nsqlite3_bind_text\n, however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.\n\n\nFinally, once completed the binding part the statement is executed and its result is returned to the client.\n\n\nThis command as well is not blocking, all the work happens in a different thread from the one of Redis.\n\n\nIf you need to query your database, without modifying the data is a better idea to use \nREDISQL.QUERY_STATEMENT\n.\n\n\nComplexity\n: The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite bindings, \nsqlite3_bind_text\n\n\nREDISQL.CREATE_STATEMENT\n\n\nRedis Blocking Command\n\n\nREDISQL.QUERY_STATEMENT\n \n\n\n\n\nREDISQL.QUERY_STATEMENT\n\n\nREDISQL.QUERY_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]\n\n\nThis command behaves similarly to \nREDISQL.EXEC_STATEMENT\n however it does impose an additional constraint.\n\n\nIt executes the statement if it is a read-only operation, otherwise, it returns an error.\n\n\nA read-only operation is defined by the result of calling \nsqlite3_stmt_readonly\n on the compiled statement.\n\n\nThe statement is executed if and only if \nsqlite3_stmt_readonly\n returns true.\n\n\nThe result of \nsqlite3_stmt_readonly\n is cached.\n\n\nIf you don't want to create a statement to run a query just once you can use \nREDISQL.QUERY\n.\n\n\nComplexity\n: Similar to \nREDISQL.EXEC_STATEMENT\n, however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.\n\n\nSee also\n:\n\n\n\n\nSQLite \nsqlite3_prepare_v2\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nSQLite \nsqlite3_step\n\n\nSQLite \nPRAGMA\ns\n\n\nRedis Blocking Command\n \n\n\nREDISQL.EXEC_STATEMENT\n\n\nSQLite \nsqlite3_stmt_readonly\n\n\nREDISQL.QUERY\n \n\n\n\n\nREDISQL.DELETE_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT[.NOW] db_key stmt_identifier\n\n\nThis command eliminates a statement from the database.\n\n\nIt first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.\n\n\nAlso, this command is not blocking and work in a different thread from the main Redis one.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nREDISQL.UPDATE_STATEMENT\n\n\nREDISQL.UPDATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"\n\n\nThe command update and \nexisting\n statement changing its internal implementation to the one provide as string.\n\n\nIf the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.\n\n\nInternally the command starts checking if the statement is already defined, then it tries to compile the string into a \nsqlite3_stmt\n and if everything went right it finally updates the metadata table and finally returns to the client.\n\n\nThis command is not blocking as well.\n\n\nComplexity\n: The complexity is constant and it can be considered \nfast\n for most practical application.\n\n\nSee also\n:\n\n\n\n\nSQLite \nstatement\n aka \nsqlite3_stmt\n\n\nREDISQL.CREATE_STATEMENT\n\n\nREDISQL.EXEC_STATEMENT\n\n\nREDISQL.DELETE_STATEMENT\n\n\nRedis Blocking Command\n\n\n\n\nVirtual Tables\n\n\nWhat follows is not a RediSQL command but an SQLite virtual table introduced by the module.\n\n\nVirtual tables behave similarly to normal tables but have some limitations, for a deeper explanation please visit the \nofficial SQLite documentation about virtual tables.\n\n\nAt the moment the module provides a single read-only virtual table: \nREDISQL_TABLES_BRUTE_HASH\n.\n\n\nREDISQL_TABLES_BRUTE_HASH\n\n\nThis virtual table allows you to query \nRedis Hashes\n that follow a similar pattern.\n\n\nA redis hash is composed by a key, that identifies the structure in the whole database, and several sub-keys that map to different string fields.\n\n\nThis structure can easily be mapped to a standard table, where the key identifies the row and the sub-keys the columns.\n\n\nRedis does not impose any limitation to the format of the hash key, however, in order to use the virtual table you need to follow a specific syntax that happens to be the de-facto standard for hash keys.\n\n\nThe key must be in the following format \n$tableName:$id\n where \n$id\n must be an integer. There are no limitations on the sub-keys.\n\n\n127.0.0.1:6379> HSET cats:1 name romeo location rome hungry 3\n(integer) 3\n127.0.0.1:6379> HSET cats:2 name garfield location london hungry 10\n(integer) 3\n127.0.0.1:6379> HSET cats:3 name \"simon's cat\" location \"simon's house\" hungry 8\n(integer) 3\n\n\n\n\nIn this examples we have a table of cats, each with a name, a location, and a hungry level.\n\n\nRedis is perfect if we want to know how hungry is \nromeo\n or where is located \ngarfield\n.\n\n\nHowever is a little more difficult to answer query like: who is the hungriest cat? Are there any cats in London? \n\n\nOf course, the use of different data structures could alleviate these issues but then there will be the necessity to keep the several data structures in sync one with the other.\n\n\nAnother alternative can be the use of the \nREDISQL_TABLE_BRUTE_HASH\n virtual table.\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM funny_cats\"\n1) 1) \"cats:2\"\n   2) \"garfield\"\n   3) \"london\"\n   4) \"10\"\n2) 1) \"cats:1\"\n   2) \"romeo\"\n   3) \"rome\"\n   4) \"3\"\n3) 1) \"cats:3\"\n   2) \"simon's cat\"\n   3) \"simon's house\"\n   4) \"8\"\n\n\n\n\nThis virtual table allows querying the redis hashes using a more convenient SQL syntax. It does require a constant amount of space but it operates in linear time with the respect of the elements in the \"hash table\".\n\n\nThe syntax of the virtual table is quite simple, \nREDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry)\n, as first we need the \n$tableName\n, so the key of every row without the \n:$id\n part. \nThen the columns of the table. Please note that you do \nnot\n provide the type of the column in the declaration.\n\n\nIs not necessary that every key defines all the columns (sub-keys), if a key does not have a specific sub-key, it will simply be returned as (nil).\n\n\nThis virtual table is a read-only virtual table, it means that -- at the moment -- you can only \nselect\n from this table, so you cannot \ninsert\n, \nupdate\n or \ndelete\n from this table.\n\n\nAnother limitation is that Redis Hashes can store only strings, not integers or floats. This implies that by default we will return only strings when you query a table, of course, you could cast them to integers or float via SQLite.\n\n\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT name, location, CAST(hungry AS INTEGER) FROM cats\"\n1) 1) \"garfield\"\n   2) \"london\"\n   3) (integer) 10\n2) 1) \"romeo\"\n   2) \"rome\"\n   3) (integer) 3\n3) 1) \"simon's cat\"\n   2) \"simon's house\"\n   3) (integer) 8\n\n\n\n\nThis specific virtual table works by continuously querying Redis itself.\n\n\nWhen you execute a \nSELECT\n against it, the first step is to \nSCAN\n all the possible keys, for each key then we retrieve the associated values in each sub-key using \nHGET\n and finally we return the result.\n\n\nComplexity\n.\n\n\nThis implementation comes with several trade-offs.\n\n\nThe space complexity is constant and negligible, no data is duplicated and are necessary only few bytes for the SQLite data structures.\n\n\nThe time complexity for a query is linear \nO(m*n)\n where \nm\n is the number of rows and \nn\n is the number of columns.\n\n\nThis virtual table does not support \nINSERT\n, \nUPDATE\n or \nDELETE\n.\n\n\nSee also\n:\n\n\n\n\nSQLite virtual tables\n\n\nRedis Hashes\n\n\nSCAN\n\n\nHGET",
            "title": "References"
        },
        {
            "location": "/references/#references",
            "text": "This document explains all the API that RediSQL provide to the users.  For each command, it exposes first the name and then the syntax and finally a brief explanation of what is going on inside the code.  Where is possible, it provides also an estimate of the complexity but since we are talking about databases not all queries have the same time and spatial complexity.  Finally, if it is appropriate the document also provides several references to external material that the interested reader can use to understand better the dynamics of every and each command.",
            "title": "References"
        },
        {
            "location": "/references/#redisqlcreate_db",
            "text": "REDISQL.CREATE_DB db_key [path]  This command creates a new DB and associates it with the key.  The path argument is optional and, if provided is the file that SQLite will use.\nIt can be an existing SQLite file or it can be a not existing file.  If the file actually exists and if it is a regular SQLite file that database will be used.\nIf the file does not exist a new file will be created.  If the path is not provided it will open an in-memory database. Not providing a path is equivalent to provide the special string  :memory:  as path argument.  After opening the database it inserts metadata into it and then starts a thread loop.  Complexity : O(1), it means constant, it does not necessarily mean  fast . However is fast enough for any use case facing human users (eg create a new database for every user logging in a website.)  See also :    SQLite  sqlite3_open_v2",
            "title": "REDISQL.CREATE_DB"
        },
        {
            "location": "/references/#del",
            "text": "DEL db_key [key ...]  This command is a generic command from Redis.  It eliminates keys from Redis itself, as well if the key is a RediSQL database create with  REDISQL.CREATE_DB  it will eliminate the SQLite database, stop the thread loop and clean up everything left.  If the database is backed by a file the file will be close.  Complexity : DEL is O(N) on the number of keys, if you are only eliminating the key associated with the SQLite database will be constant, O(1).  See also :    SQLite  sqlite3_close  Redis  DEL",
            "title": "DEL"
        },
        {
            "location": "/references/#redisqlexec",
            "text": "REDISQL.EXEC[.NOW] db_key \"statement\"  This command takes as input a Redis key created with  REDISQL.CREATE_DB  and a statement string.  Internally it transform the string into a  sqlite statement  using  sqlite3_prepare_v2 , execute it against the database,  sqlite3_step , and finally returns the results to the client.  The compilation of the string into a statement and its execution happens in a different thread from the one used by Redis and so this command has a minimum impact on the overall Redis performance, however, it does block the client.  This command is quite useful to execute  PRAGMA Statements , for normal operations against the database is suggested to use  STATEMENTS .  Also, remember that there is only a single thread for database, execution of multiple  REDISQL.EXEC  against the same database will result in a serialization of the executions, one will be executed before the others.  If you only need to query the database without modifying the data is a better idea to use  REDISQL.QUERY .  Complexity : It depends entirely on the statement string. The use of a single thread for database is been chosen after several tests where the single thread configuration was faster than a multi-thread one. This is true in a write-intensive application and in a mixed write/read application.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command",
            "title": "REDISQL.EXEC"
        },
        {
            "location": "/references/#redisqlquery",
            "text": "REDISQL.QUERY[.NOW] db_key \"statement\"  This command behaves similarly to  REDISQL.EXEC  but it imposes an additional constraint on the statement it executes.  It only executes the statement if it is a read-only operation, otherwise, it returns an error.  A read-only operation is defined by the result of calling  sqlite3_stmt_readonly  on the compiled statement.  The statement is executed if and only if  sqlite3_stmt_readonly  returns true.  If you need to execute the same query over and over it is a good idea to create a statement and use  REDISQL.QUERY_STATEMENT .  Complexity : Similar to  REDISQL.EXEC , however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command    REDISQL.EXEC  SQLite  sqlite3_stmt_readonly  REDISQL.QUERY_STATEMENT",
            "title": "REDISQL.QUERY"
        },
        {
            "location": "/references/#redisqlcreate_statement",
            "text": "REDISQL.CREATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"  This command compiles a statement string into a  sqlite statement  and associate such statement to an identifier.  Using this command you can insert parameters using the special symbol  ?NNN , those parameters will be bind to the statements when you are executing the statement itself.  For now only the  ?NNN  syntax is supported, where  N  is a digit (Ex.  ?1 ,  ?2 ,  ?3  ...)  This command does not execute anything against the database, but simply store the sqlite statements into a dictionary associated with the identifier provided ( stmt_identifier ). Then it stores the information regarding the statement in the metadata table in order to provide a simple way to restore also the statements.  The statement is associated with a database, a statement created for one database cannot be used for another database, you need to create a different one. This allows a simple and fast way to provide persistence.  You can execute the statement with  REDISQL.EXEC_STATEMENT .  You cannot overwrite a statement using this command.  If you need to change the implementation of a statement you have two options:   Delete the statement using  REDISQL.DELETE_STATEMENT  and the create a new one.  Use  REDISQL.UPDATE_STATEMENT   Suppose that a service needs a particular statement to be defined in order to work, this safety measure allows the users to simply go ahead, try to create it, and in case catch the error.  Also, this command is not blocking, meaning that all the work happens in a separate thread respect the redis one.  Please keep in mind that the parameters should be named in order and that there should not be any gap.  INSERT INTO foo VALUES(?1, ?2, ?3); -- this one is fine and we work as you expect\n\nINSERT INTO foo VALUES(?1, ?123, ?564); -- this one will be more problematic, and you should avoid it  Keep in mind that SQLite start to count the bounding parameters from 1 and not from 0, using  ?0  is an error.  Complexity : If we assume that the time necessary to compile a string into a sqlite statement is constant, overall the complexity is O(1), again constant, not necessarily  fast .  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.CREATE_STATEMENT"
        },
        {
            "location": "/references/#redisqlexec_statement",
            "text": "REDISQL.EXEC_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]  This command binds all the parameters to the statement created using  REDISQL.CREATE_STATEMENT  and identified by  stmt_identifier . Then the module executes the statement against the database associated to  db_key .  For each parameter in the query of the form  ?nnn  the engine will look for the  nnn-th  binding_parameters.\nSo if the statements is from the following query:  INSERT INTO foo VALUES(?1, ?2, ?3);  You will only need to provide 3 parameters and they will be bound, in order to  ?1 ,  ?2  and  ?3 .  If your statements looks like this:  INSERT INTO foo VALUES(?1, ?123, ?564);  You will need to provide 564 parameters and only the first, the 123-rd and the 564-th will be considered.  SQLite starts to count the binding parameters from 0, not from 1. Using  ?0  is an error.  Redis works using a text protocol, all the arguments are encoded as text, hence the module is forced to use the procedure  sqlite3_bind_text , however, SQLite is smart enough to recognize numbers and treat them correctly. Numbers will be treated as numbers and text will be treated as text.  Finally, once completed the binding part the statement is executed and its result is returned to the client.  This command as well is not blocking, all the work happens in a different thread from the one of Redis.  If you need to query your database, without modifying the data is a better idea to use  REDISQL.QUERY_STATEMENT .  Complexity : The complexity to retrieve and to bind the parameters is roughly constant for any practical purpose, however, the overall complexity will be dominated by the time to execute the query.  See also :   SQLite  statement  aka  sqlite3_stmt  SQLite bindings,  sqlite3_bind_text  REDISQL.CREATE_STATEMENT  Redis Blocking Command  REDISQL.QUERY_STATEMENT",
            "title": "REDISQL.EXEC_STATEMENT"
        },
        {
            "location": "/references/#redisqlquery_statement",
            "text": "REDISQL.QUERY_STATEMENT[.NOW] db_key stmt_identifier [binding_parameters ...]  This command behaves similarly to  REDISQL.EXEC_STATEMENT  however it does impose an additional constraint.  It executes the statement if it is a read-only operation, otherwise, it returns an error.  A read-only operation is defined by the result of calling  sqlite3_stmt_readonly  on the compiled statement.  The statement is executed if and only if  sqlite3_stmt_readonly  returns true.  The result of  sqlite3_stmt_readonly  is cached.  If you don't want to create a statement to run a query just once you can use  REDISQL.QUERY .  Complexity : Similar to  REDISQL.EXEC_STATEMENT , however, if a statement is not read-only it is aborted immediately and it does return an appropriate error.  See also :   SQLite  sqlite3_prepare_v2  SQLite  statement  aka  sqlite3_stmt  SQLite  sqlite3_step  SQLite  PRAGMA s  Redis Blocking Command    REDISQL.EXEC_STATEMENT  SQLite  sqlite3_stmt_readonly  REDISQL.QUERY",
            "title": "REDISQL.QUERY_STATEMENT"
        },
        {
            "location": "/references/#redisqldelete_statement",
            "text": "REDISQL.DELETE_STATEMENT[.NOW] db_key stmt_identifier  This command eliminates a statement from the database.  It first looks it up into the internal hash table, if it finds the statement the command removes it from the internal hash table and then remove it from an internal SQLite table.  Also, this command is not blocking and work in a different thread from the main Redis one.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.UPDATE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.DELETE_STATEMENT"
        },
        {
            "location": "/references/#redisqlupdate_statement",
            "text": "REDISQL.UPDATE_STATEMENT[.NOW] db_key stmt_identifier \"statement\"  The command update and  existing  statement changing its internal implementation to the one provide as string.  If the statement does not exist the command will fail and return an error, again this is a safety measure, you must be completely aware that you are changing the implementation of a statement and updating a not existing statement or creating an existing one will result in an error.  Internally the command starts checking if the statement is already defined, then it tries to compile the string into a  sqlite3_stmt  and if everything went right it finally updates the metadata table and finally returns to the client.  This command is not blocking as well.  Complexity : The complexity is constant and it can be considered  fast  for most practical application.  See also :   SQLite  statement  aka  sqlite3_stmt  REDISQL.CREATE_STATEMENT  REDISQL.EXEC_STATEMENT  REDISQL.DELETE_STATEMENT  Redis Blocking Command",
            "title": "REDISQL.UPDATE_STATEMENT"
        },
        {
            "location": "/references/#virtual-tables",
            "text": "What follows is not a RediSQL command but an SQLite virtual table introduced by the module.  Virtual tables behave similarly to normal tables but have some limitations, for a deeper explanation please visit the  official SQLite documentation about virtual tables.  At the moment the module provides a single read-only virtual table:  REDISQL_TABLES_BRUTE_HASH .",
            "title": "Virtual Tables"
        },
        {
            "location": "/references/#redisql_tables_brute_hash",
            "text": "This virtual table allows you to query  Redis Hashes  that follow a similar pattern.  A redis hash is composed by a key, that identifies the structure in the whole database, and several sub-keys that map to different string fields.  This structure can easily be mapped to a standard table, where the key identifies the row and the sub-keys the columns.  Redis does not impose any limitation to the format of the hash key, however, in order to use the virtual table you need to follow a specific syntax that happens to be the de-facto standard for hash keys.  The key must be in the following format  $tableName:$id  where  $id  must be an integer. There are no limitations on the sub-keys.  127.0.0.1:6379> HSET cats:1 name romeo location rome hungry 3\n(integer) 3\n127.0.0.1:6379> HSET cats:2 name garfield location london hungry 10\n(integer) 3\n127.0.0.1:6379> HSET cats:3 name \"simon's cat\" location \"simon's house\" hungry 8\n(integer) 3  In this examples we have a table of cats, each with a name, a location, and a hungry level.  Redis is perfect if we want to know how hungry is  romeo  or where is located  garfield .  However is a little more difficult to answer query like: who is the hungriest cat? Are there any cats in London?   Of course, the use of different data structures could alleviate these issues but then there will be the necessity to keep the several data structures in sync one with the other.  Another alternative can be the use of the  REDISQL_TABLE_BRUTE_HASH  virtual table.  127.0.0.1:6379> REDISQL.EXEC DB \"CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry);\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"SELECT * FROM funny_cats\"\n1) 1) \"cats:2\"\n   2) \"garfield\"\n   3) \"london\"\n   4) \"10\"\n2) 1) \"cats:1\"\n   2) \"romeo\"\n   3) \"rome\"\n   4) \"3\"\n3) 1) \"cats:3\"\n   2) \"simon's cat\"\n   3) \"simon's house\"\n   4) \"8\"  This virtual table allows querying the redis hashes using a more convenient SQL syntax. It does require a constant amount of space but it operates in linear time with the respect of the elements in the \"hash table\".  The syntax of the virtual table is quite simple,  REDISQL_TABLES_BRUTE_HASH(cats, name, location, hungry) , as first we need the  $tableName , so the key of every row without the  :$id  part. \nThen the columns of the table. Please note that you do  not  provide the type of the column in the declaration.  Is not necessary that every key defines all the columns (sub-keys), if a key does not have a specific sub-key, it will simply be returned as (nil).  This virtual table is a read-only virtual table, it means that -- at the moment -- you can only  select  from this table, so you cannot  insert ,  update  or  delete  from this table.  Another limitation is that Redis Hashes can store only strings, not integers or floats. This implies that by default we will return only strings when you query a table, of course, you could cast them to integers or float via SQLite.  127.0.0.1:6379> REDISQL.EXEC DB \"SELECT name, location, CAST(hungry AS INTEGER) FROM cats\"\n1) 1) \"garfield\"\n   2) \"london\"\n   3) (integer) 10\n2) 1) \"romeo\"\n   2) \"rome\"\n   3) (integer) 3\n3) 1) \"simon's cat\"\n   2) \"simon's house\"\n   3) (integer) 8  This specific virtual table works by continuously querying Redis itself.  When you execute a  SELECT  against it, the first step is to  SCAN  all the possible keys, for each key then we retrieve the associated values in each sub-key using  HGET  and finally we return the result.  Complexity .  This implementation comes with several trade-offs.  The space complexity is constant and negligible, no data is duplicated and are necessary only few bytes for the SQLite data structures.  The time complexity for a query is linear  O(m*n)  where  m  is the number of rows and  n  is the number of columns.  This virtual table does not support  INSERT ,  UPDATE  or  DELETE .  See also :   SQLite virtual tables  Redis Hashes  SCAN  HGET",
            "title": "REDISQL_TABLES_BRUTE_HASH"
        },
        {
            "location": "/pro/",
            "text": "RediSQL PRO\n\n\nThis document explains the architecture and principle of working of RediSQL PRO.\n\n\nYou can purchase RediSQL PRO, along with support \nhere.\n\n\nMotivation and details about the cost are \ndescribed here\n.\n\n\nMain difference\n\n\nThe PRO version offers two main features: \nnon blocking command\n and \nreplication\n\n\nNon-blocking command\n\n\nMost command in RediSQL, all but \nREDISQL.CREATE_DB\n, are blocking command.\n\n\nThis means that Redis block the client, pass the command to a background thread that actually executed it and finally the result is returned to client unblocking it.\n\n\nThis works great in most cases, the main thread of Redis is free of doing other work (like answering standard redis command), there is no difference from the client point of view and your machine can use more than the single thread of redis to work for you.\n\n\nHowever, sometimes you want to have non-blocking commands.\n\n\nThe blocking command will be executed in the main redis thread, this means that no other works will be done by Redis while executing your command.\n\n\nWe could expect the non-blocking command to be slightly faster (smaller latency) than the blocking one since there is no need for coordination between threads.\n\n\nFinally, non-blocking commands are necessary for replication.\n\n\nNon-blocking commands are invoke adding the \n.NOW\n suffix.\n\n\nAs an example, instead of \nREDISQL.EXEC\n that is a blocking command you can use \nREDISQL.EXEC.NOW\n to use the non-blocking version.\n\n\nWhen to use non-blocking commands\n\n\nNon-blocking command takes the priority over blocking one.\n\n\nSaid so, generally, we are expecting users to use mostly the blocking commands.\n\n\nHowever, if you need a very quick insert or a very quick lookup, then you should use the non-blocking version.\n\n\nIt is a bad idea to use non blocking commands for slow statements/query.\n\n\nThis because while you are executing a non-blocking command the main redis thread cannot do anything else, this means it cannot answer other redis commands.\n\n\nReplication\n\n\nRedis offers two main methods for persisting data on disk so that in case of power failure of disastrous failure your data are reasonably safe.\n\n\nRediSQL implement RDB persistency on the community version and AOF replication on the PRO version.\n\n\nFor the details of this two method, I suggest to read the Redis Documentation \non this page\n.\n\n\nThe mechanism behind AOF replication is exactly the same behind cluster replication used by redis. The same \nbytes\n used for AOF replication are also used for cluster replication, just send over different sockets.\n\n\nFor details about cluster replication you can consult the official Redis Documentation on \ncluster\n and on \nreplication\n\n\nThe PRO version, indeed, implements both AOF and cluster replication.\n\n\nEffective use of Replication\n\n\nIn order to use replication effectively, you should understand a few simple concepts.\n\n\nIf a command is replicated it means that it could be re-executed.\n\n\nIt is \nvital\n to replicate commands that change the data you are storing, however, is pointless and wasteful to replicate commands that do not apply any change to the data.\n\n\nYou definitely want to replicate every INSERTs, UPDATEs or DELETEs while you should avoid replicating SELECTs.\n\n\nReplicated commands are usually executed either when you are re-loading your dataset after some sort of failures or in slaves/replica with a train of other replicated commands is coming right after.\n\n\nConsider what happens if you replicate a big SELECT. RediSQL is going to execute it and it is going to take some time, this while your application is waiting for redis to restart or when a train of replicated commands are piling up in the slaves/replicas buffers. And all this just for discard the result of the SELECT itself.\n\n\nIn order to avoid this effect is a good idea to use the query commands whenever possible (\nREDISQL.QUERY\n and \nREDISQL.QUERY_STATEMENT\n), this command \ndo not\n replicate and are marked as \nreadonly\n which means that can be executed also on slaves/replicas providing interesting primitives of load balancing. (Eg. You could write on the master and read on the slaves.)",
            "title": "Pro"
        },
        {
            "location": "/pro/#redisql-pro",
            "text": "This document explains the architecture and principle of working of RediSQL PRO.  You can purchase RediSQL PRO, along with support  here.  Motivation and details about the cost are  described here .",
            "title": "RediSQL PRO"
        },
        {
            "location": "/pro/#main-difference",
            "text": "The PRO version offers two main features:  non blocking command  and  replication  Non-blocking command  Most command in RediSQL, all but  REDISQL.CREATE_DB , are blocking command.  This means that Redis block the client, pass the command to a background thread that actually executed it and finally the result is returned to client unblocking it.  This works great in most cases, the main thread of Redis is free of doing other work (like answering standard redis command), there is no difference from the client point of view and your machine can use more than the single thread of redis to work for you.  However, sometimes you want to have non-blocking commands.  The blocking command will be executed in the main redis thread, this means that no other works will be done by Redis while executing your command.  We could expect the non-blocking command to be slightly faster (smaller latency) than the blocking one since there is no need for coordination between threads.  Finally, non-blocking commands are necessary for replication.  Non-blocking commands are invoke adding the  .NOW  suffix.  As an example, instead of  REDISQL.EXEC  that is a blocking command you can use  REDISQL.EXEC.NOW  to use the non-blocking version.  When to use non-blocking commands  Non-blocking command takes the priority over blocking one.  Said so, generally, we are expecting users to use mostly the blocking commands.  However, if you need a very quick insert or a very quick lookup, then you should use the non-blocking version.  It is a bad idea to use non blocking commands for slow statements/query.  This because while you are executing a non-blocking command the main redis thread cannot do anything else, this means it cannot answer other redis commands.  Replication  Redis offers two main methods for persisting data on disk so that in case of power failure of disastrous failure your data are reasonably safe.  RediSQL implement RDB persistency on the community version and AOF replication on the PRO version.  For the details of this two method, I suggest to read the Redis Documentation  on this page .  The mechanism behind AOF replication is exactly the same behind cluster replication used by redis. The same  bytes  used for AOF replication are also used for cluster replication, just send over different sockets.  For details about cluster replication you can consult the official Redis Documentation on  cluster  and on  replication  The PRO version, indeed, implements both AOF and cluster replication.  Effective use of Replication  In order to use replication effectively, you should understand a few simple concepts.  If a command is replicated it means that it could be re-executed.  It is  vital  to replicate commands that change the data you are storing, however, is pointless and wasteful to replicate commands that do not apply any change to the data.  You definitely want to replicate every INSERTs, UPDATEs or DELETEs while you should avoid replicating SELECTs.  Replicated commands are usually executed either when you are re-loading your dataset after some sort of failures or in slaves/replica with a train of other replicated commands is coming right after.  Consider what happens if you replicate a big SELECT. RediSQL is going to execute it and it is going to take some time, this while your application is waiting for redis to restart or when a train of replicated commands are piling up in the slaves/replicas buffers. And all this just for discard the result of the SELECT itself.  In order to avoid this effect is a good idea to use the query commands whenever possible ( REDISQL.QUERY  and  REDISQL.QUERY_STATEMENT ), this command  do not  replicate and are marked as  readonly  which means that can be executed also on slaves/replicas providing interesting primitives of load balancing. (Eg. You could write on the master and read on the slaves.)",
            "title": "Main difference"
        },
        {
            "location": "/motivations/",
            "text": "Motivation\n\n\nThis document explains the motivations behind this redis module.\n\n\nMy personal use case\n\n\nAs a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.\n\n\nI was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.\n\n\nRedis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.\n\n\nHowever, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.\n\n\nAt that time I had only the following options:\n\n\n\n\nKeep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.\n\n\nBring in another piece inside my architecture, namely an SQL database.\n\n\n\n\nFor some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.\n\n\nOperating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.\n\n\nAlso, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.\n\n\nMy project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.\n\n\nWhy RediSQL\n\n\nThe goal of the module is to create a third alternative to the two mentioned above.\n\n\nI wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.\n\n\nSQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.\n\n\nFinally, merging the two project was just made possible by the introduction of the Redis modules.\n\n\nHence, RediSQL was born.\n\n\nPossible uses\n\n\nRediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.\n\n\nHowever, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.\n\n\nMoreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.\n\n\nThis makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Motivations"
        },
        {
            "location": "/motivations/#motivation",
            "text": "This document explains the motivations behind this redis module.",
            "title": "Motivation"
        },
        {
            "location": "/motivations/#my-personal-use-case",
            "text": "As a lot of different open source projects, this module is born out of a personal issue that I was trying to solve.  I was developing a very simple application using a microservice architecture, each service needed to be stopped and updated at will so it was mandatory to store all the state in an external application.  Redis was perfect for this use case since it is very simple to operate, you could get away simply setting your level of persistence, extremely stable, very performant and there are bindings ready for basically any programming language.  However, the application started to grow in terms of complexity and soon I realized that having a small SQL engine would have saved me a lot of complexity in my code while delivering better performances.  At that time I had only the following options:   Keep all the state in Redis, implementing by hand, or using some external library, whatever SQL-like transformation I needed.  Bring in another piece inside my architecture, namely an SQL database.   For some project it may be worth to immediately include an external dependency in the form of a database, but it brings up the cost of operating the infrastructure.  Operating a database is quite complex, operating it in any organization costs in terms of human resources or, if you use managed services, directly in terms of money.  Also, since all my state was kept only in Redis, introducing another \"source of truth\" would have complicated the code base.  My project definitely didn't need the whole computing power of Postgresql or of MySQL, I didn't need the burden of operating it and definitely I wasn't in the condition to pay for managed services.",
            "title": "My personal use case"
        },
        {
            "location": "/motivations/#why-redisql",
            "text": "The goal of the module is to create a third alternative to the two mentioned above.  I wanted this alternative to be as low maintenance as possible, keep a great level of security on the persistency of the data stored and to be easily deployed in most architectures.  SQLite easily checks both the low maintenance and the high level of persistency requirements. Redis is already deployed in most architectures, either as a cache layer or as a database.  Finally, merging the two project was just made possible by the introduction of the Redis modules.  Hence, RediSQL was born.",
            "title": "Why RediSQL"
        },
        {
            "location": "/motivations/#possible-uses",
            "text": "RediSQL has been thought to be used as an in-memory SQL database, shared between multiple (micro-)services.  However, RediSQL inherits the persistency capabilities of Redis, supporting RDB and AOF, and of SQLite, with the possibility to write directly on disk.  Moreover, it basically never uses the main thread of Redis, hence it will not affect the performance of Redis itself.  This makes RediSQL a reasonable solution to store and persist data in a small to a medium modern project.",
            "title": "Possible uses"
        },
        {
            "location": "/pro_motivations/",
            "text": "RediSQL PRO Motivation\n\n\nThis document explains why we decide to offer a commercial PRO version alongside the free and open source community version.\n\n\ntl;dr;\n\n\n\n\nWe sell a PRO version to make the project sustainable.\n\n\nYou can buy the PRO version \nhere.\n\n\nWe offer custom license term if your company need one.\n\n\n\n\nNecessity to make the project sustainable\n\n\nWe believe that in order to provide the most value Open Source should be sustainable.\n\n\nDesign, implementation and testing are all necessary and valuable steps of any software project, but they do require time.\n\n\nOpen sources projects that are able to really deliver value need to find a way to remunerate the time of their maintainers.\n\n\nSome successful open source projects are backed by companies (Firefox, React, etc...), other sell supports (mongodb, vernemq, etc...) and other plug their software into a commercial offer (npm, docker, elatic, etc...).\n\n\nOur approach\n\n\nIn order to provide a open source, our approach is to offer two different product, a completely free open source one and a PRO version.\n\n\nSelling the PRO version allows us to dedicate most of the time to the project, having a good work-life balance, enjoy time with our girlfriends, wives or kids and being productive developers and technical writers.\n\n\nBenefits for organizations and for the community\n\n\nMoreover, we believe that this is the best way to serve our users and the community.\n\n\nIndeed, we are able to maintain the project through the years so that any company or organization that decide to use our product will know that in 3/4/5 years we will still be there to help them if any problem should arise.\n\n\nOn top of this also single programmers, very small start-ups or small companies will benefit from us keeping maintaining the product in its two form, community and pro.\n\n\nYou can support us and buy the commercial version of this product \non this web page.\n\n\nWe also offer \ncustom license terms\n if your organization needs one.\n\n\nAbout the cost\n\n\nWe set up the cost (\u20ac990 / year) to make it a bargain for every company that actually uses it.\n\n\nConsidering the amount of time necessary to replicate the PRO features:\n\n\n\n\nUnderstand the working principle of Redis\n\n\nUnderstand SQLite and how to leverage it\n\n\nUnderstand the Redis Module API\n\n\nDesign the product\n\n\nImplement it\n\n\nTest it\n\n\nDocument it\n\n\nMaintain it\n\n\n\n\nMultiply it by the hourly rate of a software engineer (~100 \u20ac/hours).\n\n\nIt is clear that after a little more than a single day of work our product will be a net positive for your organization.\n\n\nMoreover, the PRO version comes with \nsupport plan\n to help you extract the most value out of the product.\n\n\nFinally, we offer custom, business-friendly licenses if your business or lawyers need them.",
            "title": "PRO Motivations"
        },
        {
            "location": "/pro_motivations/#redisql-pro-motivation",
            "text": "This document explains why we decide to offer a commercial PRO version alongside the free and open source community version.",
            "title": "RediSQL PRO Motivation"
        },
        {
            "location": "/pro_motivations/#tldr",
            "text": "We sell a PRO version to make the project sustainable.  You can buy the PRO version  here.  We offer custom license term if your company need one.",
            "title": "tl;dr;"
        },
        {
            "location": "/pro_motivations/#necessity-to-make-the-project-sustainable",
            "text": "We believe that in order to provide the most value Open Source should be sustainable.  Design, implementation and testing are all necessary and valuable steps of any software project, but they do require time.  Open sources projects that are able to really deliver value need to find a way to remunerate the time of their maintainers.  Some successful open source projects are backed by companies (Firefox, React, etc...), other sell supports (mongodb, vernemq, etc...) and other plug their software into a commercial offer (npm, docker, elatic, etc...).",
            "title": "Necessity to make the project sustainable"
        },
        {
            "location": "/pro_motivations/#our-approach",
            "text": "In order to provide a open source, our approach is to offer two different product, a completely free open source one and a PRO version.  Selling the PRO version allows us to dedicate most of the time to the project, having a good work-life balance, enjoy time with our girlfriends, wives or kids and being productive developers and technical writers.",
            "title": "Our approach"
        },
        {
            "location": "/pro_motivations/#benefits-for-organizations-and-for-the-community",
            "text": "Moreover, we believe that this is the best way to serve our users and the community.  Indeed, we are able to maintain the project through the years so that any company or organization that decide to use our product will know that in 3/4/5 years we will still be there to help them if any problem should arise.  On top of this also single programmers, very small start-ups or small companies will benefit from us keeping maintaining the product in its two form, community and pro.  You can support us and buy the commercial version of this product  on this web page.  We also offer  custom license terms  if your organization needs one.",
            "title": "Benefits for organizations and for the community"
        },
        {
            "location": "/pro_motivations/#about-the-cost",
            "text": "We set up the cost (\u20ac990 / year) to make it a bargain for every company that actually uses it.  Considering the amount of time necessary to replicate the PRO features:   Understand the working principle of Redis  Understand SQLite and how to leverage it  Understand the Redis Module API  Design the product  Implement it  Test it  Document it  Maintain it   Multiply it by the hourly rate of a software engineer (~100 \u20ac/hours).  It is clear that after a little more than a single day of work our product will be a net positive for your organization.  Moreover, the PRO version comes with  support plan  to help you extract the most value out of the product.  Finally, we offer custom, business-friendly licenses if your business or lawyers need them.",
            "title": "About the cost"
        },
        {
            "location": "/blog/analytics/",
            "text": "RediSQL for analytics\n\n\nRediSQL is a module for Redis that embed a completely functional SQLite database. \n\n\nRediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.\n\n\nIn this blog post, we are going to explore how RediSQL can be used for storing analytics data.\n\n\nRedis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.\n\n\nWe are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.\n\n\nAt the end of the article, there is actual python code that you can run.\n\n\nProblem\n\n\nSuppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.\n\n\nAll these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.\n\n\nHowever, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.\n\n\nData Structure\n\n\nOne of the advantages of using SQL is the possibility to use and declare the shape of your data.\n\n\nFor this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.\n\n\nWe are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.\n\n\nEvents\n\n\nRepresenting the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.\n\n\nHowever you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.\n\n\nJSON or Tables\n\n\nIf your events are quite static and you already know what you are going to store the best approach is to use tables.\n\n\nAn idea could be to use this representation for the table \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|\n\n\n\n\nAnd then different tables for each type of events, like:\n\n\nSales\n:\n\n\n| event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|\n\n\n\n\nSubmits\n:\n\n\n| event_id | url_page | A/B_version |\n|----------|----------|-------------|\n\n\n\n\nWhere \nevent_id\n is a Primary key to the table \nEvents\n and a Foreign key on the table \nSales\n and \nSubmits\n.\n\n\nThis approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.\n\n\nA different approach will be to store directly JSON in your table.\n\n\nThe new schema will be only a single table, \nEvents\n:\n\n\n| event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|\n\n\n\n\nThe column data will be of type \ntext\n and it will store anything you want if encoded in JSON.\n\n\nOf course, it is also possible to run any kind of computation on the JSON data including filters and selection.\n\n\nUsing JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.\n\n\nSolution Sketch\n\n\nIn this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.\n\n\nI am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out \nthe readme of the project\n\n\nWe are going to automate as much as possible in this tutorial, in this way your analytic script will just run.\n\n\nThe very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.\n\n\nimport redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)\n\n\n\n\nNow that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy, \nDB\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"\n\n\n\n\nNow that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.\n\n\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]\n\n\n\n\nSetting the type of \nevent_id\n as \nINTEGER PRIMARY KEY\n is synonymous with \nROWID\n which is an autoincrement fields that do not need to be set during insert.\n\n\nAt this point, the only thing left to do is to listen for events in your code and write them into the database.\n\n\nThe simplest, and insecure, way to write the data is to use the \nEXEC\n function like so:\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]\n\n\n\n\nAs you may have guessed already the return value of \nREDISQL.EXEC\n is a list of two elements, the string \nDONE\n and the integer representing the number of rows modified (inserted, deleted or updated).\n\n\nHowever, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.\n\n\nThe better and safer way to do this kind of operation is to define \nstatements\n.\n\n\nok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"\n\n\n\n\nOnce a statement is defined you can execute it using the following commands.\n\n\n# import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]\n\n\n\n\nThe use of statements brings some benefits.\n\n\n\n\nIt reduces code deduplication in your code base\n\n\nIt puts a name on a particular procedure, decoupling the implementation and the goal\n\n\nIt allows different microservices to invoke the always the exact same procedure\n\n\nIt is faster to execute\n\n\n\n\nUse the JSON1 SQLite module\n\n\nNow that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.\n\n\nThe ones that follow are plain SQL statements that you can execute \nREDISQL.EXEC\n against the database or that you can embed into a statement.\n\n\nThe most interesting function provide is \njson_extract\n.\n\n\nSELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";\n\n\n\n\nThis query will look inside the field \ntype\n of the JSON stored into the columns \ndata\n if this fields contains the string \"sales\" it will return the user who bought something and total of the sale. \n\n\njson_extract\n works also on array using a simple syntax: \n$.array[2]\n (eg. extract the third element of the array)\n\n\nMove the data\n\n\nRunning the above script will be extremely fast, I am talking about 10ks inserts per second fast.\n\n\nHowever, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.\n\n\nThis can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.\n\n\nThe simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.\n\n\nA quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.\n\n\nThis operation is quite simple and it can be done like so.\n\n\n# get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)\n\n\n\n\nNow you can use tools like PostgreSQL COPY to load all the data into your database.\n\n\nThis solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.\n\n\nRecap\n\n\nIn this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.\n\n\nAdding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.\n\n\nIs worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Analytics"
        },
        {
            "location": "/blog/analytics/#redisql-for-analytics",
            "text": "RediSQL is a module for Redis that embed a completely functional SQLite database.   RediSQL enables new paradigm where is possible to have several smaller decentralized databases instead of a single giant one.  In this blog post, we are going to explore how RediSQL can be used for storing analytics data.  Redis is always been used for storing fast data and so it is an extremely interesting software for analytics solution.  We are now going to describe the problem, explore some data structures that may help and finally sketch a possible solution using RediSQL.  At the end of the article, there is actual python code that you can run.",
            "title": "RediSQL for analytics"
        },
        {
            "location": "/blog/analytics/#problem",
            "text": "Suppose you are interested in following the user around your website, and you will like to know what buttons they click, what events they trigger, what form the focus on and so on and so forth.  All these events are quite simple to catch using javascript and client-side code, but then you need to store them in your database to analyze them further and extract new information and value for your business.  However, you would prefer to avoid to put too much pressure on your main database that is already busy storing all the essential information for the business.",
            "title": "Problem"
        },
        {
            "location": "/blog/analytics/#data-structure",
            "text": "One of the advantages of using SQL is the possibility to use and declare the shape of your data.  For this specific problem, our data are quite simple.\nWe want to store a user identifier (it may be its alias, nickname, ID in the main database or even something else), the IP address of the user, the timestamp when the event was triggered and finally the event itself.  We are going to represent the identifier, the IP address and the timestamp as strings.\nYes, unfortunately, SQLite does not provide a time type, to use a string is quite a reasonable choice, another one could be to use integers and to save the timestamp as Unix epoch of the event.  Events  Representing the events may be a little complex and it really depends on your use case.\nSuppose you are just listening to specific events like \"Sales\", \"Register\", \"Login\" or \"Submit form\" you could simply store them as strings.  However you can be a little more sophisticated as well, and associate to every Sales some other data like \"amount\", \"shipping cost\" or \"total elements sold\" or again improve the \"Submit form\" with information about the web page, like the URL of the page or if it was the A or the B version of your A/B test. And so on and so forth.  JSON or Tables  If your events are quite static and you already know what you are going to store the best approach is to use tables.  An idea could be to use this representation for the table  Events :  | event_id | user_id | ip_address | timestamp |\n|----------|---------|------------|-----------|  And then different tables for each type of events, like:  Sales :  | event_id | amount  | shipping_cost | total_elements_sold |\n|----------|---------|---------------|---------------------|  Submits :  | event_id | url_page | A/B_version |\n|----------|----------|-------------|  Where  event_id  is a Primary key to the table  Events  and a Foreign key on the table  Sales  and  Submits .  This approach works really well, the shape of your data will be always known and it will be fast, however, you actually need to know what you are saving in your DB and change the structure of the table is quite complex.  A different approach will be to store directly JSON in your table.  The new schema will be only a single table,  Events :  | event_id | user_id | ip_address | timestamp | data |\n|----------|---------|------------|-----------|------|  The column data will be of type  text  and it will store anything you want if encoded in JSON.  Of course, it is also possible to run any kind of computation on the JSON data including filters and selection.  Using JSON you gain a lot of flexibility but you are not sure anymore of the shape of your data and if you are not careful it may cause some headaches.",
            "title": "Data Structure"
        },
        {
            "location": "/blog/analytics/#solution-sketch",
            "text": "In this section we are going to get through a possible implementation of the above solution, we are going to use the JSON variant since I believe that not everybody knew that SQLite could handle JSON so well.  I am assuming you already know how to get a Redis instance and how to load a module into it, if not make sure to check out  the readme of the project  We are going to automate as much as possible in this tutorial, in this way your analytic script will just run.  The very first thing to do is to get a working connection to your Redis instance, any Redis binding should make this process quite simple, here an example in python.  import redis\nr = redis.StrictRedis(host='localhost', port=6379, db=0)  Now that you have established a connection the next step is to create a RediSQL database, RediSQL can manage multiple, completely independent databases, each associated with a Redis key, for this simple example we are going to use only one database that, with a lot of fantasy,  DB .  ok = r.execute_command(\"REDISQL.CREATE_DB\", \"DB\")\nassert ok == \"OK\"  Now that we have created our database we can go ahead and create the table that will contain our data. We are going to create the table if and only if it does not exists yet.  done = r.execute_command(\"REDISQL.EXEC\", \"DB\", \n                         \"\"\"CREATE TABLE\n                            IF NOT EXISTS \n                            Events(\n                                event_id INTEGER PRIMARY KEY,\n                                user_id STRING,\n                                ip_address STRING,\n                                timestamp STRING,\n                                data JSON\n                            );\"\"\")\nassert done == [\"DONE\", 0]  Setting the type of  event_id  as  INTEGER PRIMARY KEY  is synonymous with  ROWID  which is an autoincrement fields that do not need to be set during insert.  At this point, the only thing left to do is to listen for events in your code and write them into the database.  The simplest, and insecure, way to write the data is to use the  EXEC  function like so:  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\nstatement = \"\"\"INSERT INTO Events (user_id, ip_address, timestamp, data) \n               VALUES(\\\"{}\\\", \\\"{}\\\", \\\"{}\\\", \\\"{}\\\")\"\"\" \\\n               .format(user_id, ip_address, now, data)\ndone = r.execute_command(\"REDISQL.EXEC\", \"DB\", statement)\nassert done == [\"DONE\", 1]  As you may have guessed already the return value of  REDISQL.EXEC  is a list of two elements, the string  DONE  and the integer representing the number of rows modified (inserted, deleted or updated).  However, this way of inserting data into the database is not optimal, especially if the same operation will be performed several times. And also because it is vulnerable to SQL injections attacks.  The better and safer way to do this kind of operation is to define  statements .  ok = r.execute_command(\"REDISQL.CREATE_STATEMENT\", \"DB\", \"insert_event\",\n                       \"\"\"INSERT INTO Events \n                          (user_id, ip_address, timestamp, data) \n                          VALUES(?1, ?2, ?3, ?4)\"\"\")\nassert ok == \"OK\"  Once a statement is defined you can execute it using the following commands.  # import datetime\nuser_id = \"user_1234\"\nip_address = \"a.simple.ip.address\"\nnow = datetime.datetime.now()\ndata = {\"type\" : \"sales\", \"total\": 1999, \"shipping_address\" : \"...\"}\ndone = r.execute_command(\"REDISQL.EXEC_STATEMENT\", \"DB\", \"insert_event\", user_id, ip_address, now, data)\nassert done == [\"DONE\", 1]  The use of statements brings some benefits.   It reduces code deduplication in your code base  It puts a name on a particular procedure, decoupling the implementation and the goal  It allows different microservices to invoke the always the exact same procedure  It is faster to execute   Use the JSON1 SQLite module  Now that we have covered how to execute SQL against RediSQL let me quickly introduce you to the JSON1 syntax provide by SQLite.  The ones that follow are plain SQL statements that you can execute  REDISQL.EXEC  against the database or that you can embed into a statement.  The most interesting function provide is  json_extract .  SELECT user_id, json_extract(data, '$.total')\nFROM Events\nWHERE json_extract(data, '$.type') = \"sales\";  This query will look inside the field  type  of the JSON stored into the columns  data  if this fields contains the string \"sales\" it will return the user who bought something and total of the sale.   json_extract  works also on array using a simple syntax:  $.array[2]  (eg. extract the third element of the array)",
            "title": "Solution Sketch"
        },
        {
            "location": "/blog/analytics/#move-the-data",
            "text": "Running the above script will be extremely fast, I am talking about 10ks inserts per second fast.  However, it is so fast for a variety of reason but maybe the most important is that it keeps all the data in memory and does not write them on disk.  This can be just fine for some application (think about storing data that become useless in few days time) or it can be a big issue for some other use case, luckily there is a very simple solution.  The simplest thing to do when you decide to dump the data in your persistent storage is just to query them all and push them, in batch, to your persistent system. Moving the data in all together will allow having an extremely high throughput and it will take a fraction of the time than if you moved just a row at the time.  A quite simple practice is to simply dump all the content of your database in a CSV file and then let your RDBMS load it.  This operation is quite simple and it can be done like so.  # get the data\nvalues = r.execute_command(\"REDISQL.EXEC\", \"DB\", \"SELECT * FROM Events;\")\n# iterate throught the list writing on file\nwith open('csv_file', 'w') as csv_file:\n    # write the csv header\n    csv_file.write(\"event_id,user_id,ip_address,timestamp,data\\n\")\n    for row in values:\n        # create a single string with all the fields separated by a comma\n        elements = \",\".join(row) + \"\\n\"\n        # write the result on the csv_file\n        csv_file.write(elements)  Now you can use tools like PostgreSQL COPY to load all the data into your database.  This solution is not perfect and in a distributed setting with several concurrent workers it may result in some data duplication, however, we are getting ahead of ourselves and this topic will go far ahead of the scope of this post.",
            "title": "Move the data"
        },
        {
            "location": "/blog/analytics/#recap",
            "text": "In this blog post, we explored how to write a quite sophisticated analytics infrastructure using nothing more than RediSQL.  Adding this tool to your existing infrastructure should be quite simple and painless while it provides a simple way to do powerful things in a fast and reliable way.  Is worth to remember that RediSQL already provide RDB persistency so you already have some interesting level of safeness embed into this architecture.",
            "title": "Recap"
        },
        {
            "location": "/blog/JaaS/",
            "text": "JSON on Redis via RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr; We build a \nJSON as a Service\n in less than 500 lines of javascript + RediSQL, you can check out the \nwhole source file here.\n\n\nJSON as a Service in 500 lines of code + RediSQL\n\n\nWhile building web services is common to have the need to store some un-structured or semi-structured data (aka \nJSON\n) somewhere.\n\n\nUnfortunately, it is not always so easy.\n\n\nIf you are using a SQL database, think about postgres, you need to add a column or even a table to your database, you need to decide how to encode the data and to be sure that your drivers work correctly with this new type.\n\n\nIf you are already using some kind of NoSQL database you may be a little luckier, but nevertheless, you should be sure that your database support all the operation you may need on JSON and still you need your team on-board to add a new collection/fields/column to your actual database.\n\n\nA faster solution\n\n\nA faster solution could be to use RediSQL exploiting the \nJSON1\n extension.\n\n\nSQLite provides several interesting extensions and one of our favourites is JSON1 that allow an efficient and fast manipulation of JSON data, all inside a full SQL engine.\n\n\nWe include this extension by default in RediSQL, so, if you are using RediSQL, you already have all the necessary function.\n\n\nDesiderata\n\n\nIn this example we assume that you are sharing your JSON data store between different part of the system, hence you need some form of hierarchy.\n\n\nWe will create JSON object that will have names and then each object will live inside a namespace, the couple \n(namespace, name)\n will be unique while name could be repeated inside different namespaces.\n\n\nThen we will like to have a simple RediSQL interface like this one:\n\n\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace noises\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises animals '{\"cat\": \"meeow\", \"dog\": \"woof\", \"goldfish\": \"...\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises humans '{\"extrovert\": \"blablabla\", \"introverse\": \"bla\", \"programmer\": \"tap tap tap\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises humans $.extrovert\n1) 1) \"blablabla\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises animals $.dog\n1) 1) \"woof\"\n127.0.0.1:6379> \n\n\n\n\nOf course, we would also like to navigate complex JSONs and to add fields and values at will.\n\n\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace foo\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object foo bar '{\"a\": {\"quite\": [\"\", {\"complex\": {\"json\": [1, 2, \"object\"]}}, \"\"]}}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[2]\n1) 1) \"object\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB set foo bar $.a.quite[1].complex.json[3] '[\"even\", \"more\", \"complex\"]'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3] \n1) 1) \"[\\\"even\\\",\\\"more\\\",\\\"complex\\\"]\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][0]\n1) 1) \"even\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][1]\n1) 1) \"more\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][2]\n1) 1) \"complex\"\n\n\n\n\nIn this specific example we are only showing JSON, but keep in mind that the JSON field can be stored alongside the regular SQL fields as an extra field to hold any kind of unstructured data.\n\n\nAlso please note how these APIs are quite pleasant to work with, they seem almost native to redis and thanks to redis-module we have the possibility to simply create more powerful commands. \n\n\nImplementation\n\n\nNow that we know what we are trying to achieve let's proceed to the implementation that you will see is quite simple.\n\n\nUsually is a good idea to start from the data structure, and in our simple, but powerful, example, we need only a single table:\n\n\nCREATE TABLE IF NOT EXISTS namespace ( \n    namespace TEXT PRIMARY KEY \n); \n\nCREATE TABLE IF NOT EXISTS json_data (\n    namespace STRING,\n    object_name STRING,\n    data JSON,\n    PRIMARY KEY (namespace, object_name),\n    FOREIGN KEY(namespace) REFERENCES namespace(namespace) ON UPDATE CASCADE ON DELETE CASCADE\n);\n\n\n\n\nWe could have done everything with just \njson_data\n and without \nnamespace\n, but that would force to have the namespace that always contains at least a single object and everything would become more complex.\n\n\nNow that we have our data structure we can proceed with the procedures that I have show you above:\n\n\n-- create_namespace\nINSERT INTO namespace VALUES(?1);\n\n-- upsert_object\nINSERT OR REPLACE \n        INTO json_data (namespace, object_name, data)\n        VALUES (?1, ?2, json(?3))\n\n-- get_object\nSELECT data \n        FROM json_data \n        WHERE namespace = ?1 AND\n        object_name = ?2;\n\n-- extract\nSELECT json_extract(data, ?3) \n        FROM json_data \n        WHERE namespace = ?1 AND \n        object_name = ?2;\n\n-- set\nUPDATE json_data \n        SET data = json_set(data, ?3, json(?4))\n        WHERE namespace = ?1 AND \n        object_name = ?2 AND\n        data != json_set(data, ?3, json(?4)); -- if no modification, don't change the object\n\n\n\n\nIn order to actually create those table here is an example on RediSQL that is more difficult to read but simpler to just copy and paste into the redis-cli.\n\n\n127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS namespace (namespace TEXT PRIMARY KEY);\" \n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS json_data (namespace STRING, object_name STRING, data JSON, PRIMARY KEY (namespace, object_name));\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB create_namespace \"INSERT INTO namespace VALUES(?1);\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB upsert_object \"INSERT OR REPLACE INTO json_data (namespace, object_name, data) VALUES (?1, ?2, json(?3))\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB get_object \"SELECT data FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB extract \"SELECT json_extract(data, ?3) FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB set \"UPDATE json_data SET data = json_set(data, ?3, json(?4)) WHERE namespace = ?1 AND object_name = ?2 AND data != json_set(data, ?3, json(?4));\"\nOK\n\n\n\n\nOf course, there are a lot more commands in JSON1 API to use and explore, so I will simply \nleave you the reference\n.\n\n\nI also prepare a simple node application which exposes this exact same interface via REST API, it is a single, ~500 LOC, file that you can find \nhere\n\n\nFeel free to use the node application as a blueprint for your next project.\n\n\nRecap\n\n\nIn this brief tutorial, we have shown how quickly and easily is possible to build a fairly complex JSON store using Redis and RediSQL.\n\n\nOf course, similar structures, procedure and ideas can be used inside bigger structures and data table yielding powerful primitives for your application capable of sustain quite reasonable load without incurring in any extra operational cost.\n\n\nQuestion?\n\n\nOf course, if you have any question on RediSQL either open a public issue or write me, siscia, a private email.\n\n\nCheers,\n\n\n;)",
            "title": "JSON on Redis using RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/JaaS/#json-on-redis-via-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.  The fastest introduction to RediSQL is  our homepage  tl;dr; We build a  JSON as a Service  in less than 500 lines of javascript + RediSQL, you can check out the  whole source file here.",
            "title": "JSON on Redis via RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/JaaS/#json-as-a-service-in-500-lines-of-code-redisql",
            "text": "While building web services is common to have the need to store some un-structured or semi-structured data (aka  JSON ) somewhere.  Unfortunately, it is not always so easy.  If you are using a SQL database, think about postgres, you need to add a column or even a table to your database, you need to decide how to encode the data and to be sure that your drivers work correctly with this new type.  If you are already using some kind of NoSQL database you may be a little luckier, but nevertheless, you should be sure that your database support all the operation you may need on JSON and still you need your team on-board to add a new collection/fields/column to your actual database.",
            "title": "JSON as a Service in 500 lines of code + RediSQL"
        },
        {
            "location": "/blog/JaaS/#a-faster-solution",
            "text": "A faster solution could be to use RediSQL exploiting the  JSON1  extension.  SQLite provides several interesting extensions and one of our favourites is JSON1 that allow an efficient and fast manipulation of JSON data, all inside a full SQL engine.  We include this extension by default in RediSQL, so, if you are using RediSQL, you already have all the necessary function.",
            "title": "A faster solution"
        },
        {
            "location": "/blog/JaaS/#desiderata",
            "text": "In this example we assume that you are sharing your JSON data store between different part of the system, hence you need some form of hierarchy.  We will create JSON object that will have names and then each object will live inside a namespace, the couple  (namespace, name)  will be unique while name could be repeated inside different namespaces.  Then we will like to have a simple RediSQL interface like this one:  127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace noises\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises animals '{\"cat\": \"meeow\", \"dog\": \"woof\", \"goldfish\": \"...\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object noises humans '{\"extrovert\": \"blablabla\", \"introverse\": \"bla\", \"programmer\": \"tap tap tap\"}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises humans $.extrovert\n1) 1) \"blablabla\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract noises animals $.dog\n1) 1) \"woof\"\n127.0.0.1:6379>   Of course, we would also like to navigate complex JSONs and to add fields and values at will.  127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB create_namespace foo\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB upsert_object foo bar '{\"a\": {\"quite\": [\"\", {\"complex\": {\"json\": [1, 2, \"object\"]}}, \"\"]}}'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[2]\n1) 1) \"object\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB set foo bar $.a.quite[1].complex.json[3] '[\"even\", \"more\", \"complex\"]'\n1) DONE\n2) (integer) 1\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3] \n1) 1) \"[\\\"even\\\",\\\"more\\\",\\\"complex\\\"]\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][0]\n1) 1) \"even\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][1]\n1) 1) \"more\"\n127.0.0.1:6379> REDISQL.EXEC_STATEMENT DB extract foo bar $.a.quite[1].complex.json[3][2]\n1) 1) \"complex\"  In this specific example we are only showing JSON, but keep in mind that the JSON field can be stored alongside the regular SQL fields as an extra field to hold any kind of unstructured data.  Also please note how these APIs are quite pleasant to work with, they seem almost native to redis and thanks to redis-module we have the possibility to simply create more powerful commands.",
            "title": "Desiderata"
        },
        {
            "location": "/blog/JaaS/#implementation",
            "text": "Now that we know what we are trying to achieve let's proceed to the implementation that you will see is quite simple.  Usually is a good idea to start from the data structure, and in our simple, but powerful, example, we need only a single table:  CREATE TABLE IF NOT EXISTS namespace ( \n    namespace TEXT PRIMARY KEY \n); \n\nCREATE TABLE IF NOT EXISTS json_data (\n    namespace STRING,\n    object_name STRING,\n    data JSON,\n    PRIMARY KEY (namespace, object_name),\n    FOREIGN KEY(namespace) REFERENCES namespace(namespace) ON UPDATE CASCADE ON DELETE CASCADE\n);  We could have done everything with just  json_data  and without  namespace , but that would force to have the namespace that always contains at least a single object and everything would become more complex.  Now that we have our data structure we can proceed with the procedures that I have show you above:  -- create_namespace\nINSERT INTO namespace VALUES(?1);\n\n-- upsert_object\nINSERT OR REPLACE \n        INTO json_data (namespace, object_name, data)\n        VALUES (?1, ?2, json(?3))\n\n-- get_object\nSELECT data \n        FROM json_data \n        WHERE namespace = ?1 AND\n        object_name = ?2;\n\n-- extract\nSELECT json_extract(data, ?3) \n        FROM json_data \n        WHERE namespace = ?1 AND \n        object_name = ?2;\n\n-- set\nUPDATE json_data \n        SET data = json_set(data, ?3, json(?4))\n        WHERE namespace = ?1 AND \n        object_name = ?2 AND\n        data != json_set(data, ?3, json(?4)); -- if no modification, don't change the object  In order to actually create those table here is an example on RediSQL that is more difficult to read but simpler to just copy and paste into the redis-cli.  127.0.0.1:6379> REDISQL.CREATE_DB DB\nOK\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS namespace (namespace TEXT PRIMARY KEY);\" \n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.EXEC DB \"CREATE TABLE IF NOT EXISTS json_data (namespace STRING, object_name STRING, data JSON, PRIMARY KEY (namespace, object_name));\"\n1) DONE\n2) (integer) 0\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB create_namespace \"INSERT INTO namespace VALUES(?1);\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB upsert_object \"INSERT OR REPLACE INTO json_data (namespace, object_name, data) VALUES (?1, ?2, json(?3))\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB get_object \"SELECT data FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB extract \"SELECT json_extract(data, ?3) FROM json_data WHERE namespace = ?1 AND object_name = ?2;\"\nOK\n127.0.0.1:6379> REDISQL.CREATE_STATEMENT DB set \"UPDATE json_data SET data = json_set(data, ?3, json(?4)) WHERE namespace = ?1 AND object_name = ?2 AND data != json_set(data, ?3, json(?4));\"\nOK  Of course, there are a lot more commands in JSON1 API to use and explore, so I will simply  leave you the reference .  I also prepare a simple node application which exposes this exact same interface via REST API, it is a single, ~500 LOC, file that you can find  here  Feel free to use the node application as a blueprint for your next project.",
            "title": "Implementation"
        },
        {
            "location": "/blog/JaaS/#recap",
            "text": "In this brief tutorial, we have shown how quickly and easily is possible to build a fairly complex JSON store using Redis and RediSQL.  Of course, similar structures, procedure and ideas can be used inside bigger structures and data table yielding powerful primitives for your application capable of sustain quite reasonable load without incurring in any extra operational cost.",
            "title": "Recap"
        },
        {
            "location": "/blog/JaaS/#question",
            "text": "Of course, if you have any question on RediSQL either open a public issue or write me, siscia, a private email.  Cheers,  ;)",
            "title": "Question?"
        },
        {
            "location": "/blog/performances/",
            "text": "Doubling the performances of RediSQL, SQL steroids for Redis.\n\n\nRediSQL provides SQL steroids for Redis\n\n\nRediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr; We double the performance of RediSQL switching to a zero-copy use of the input arguments.\n\n\nBackground\n\n\nDuring the development of RediSQL we always kept in mind performance, but only up to a degree.\n\n\nAs Donal Knuth says \"premature optimization is the root of all evil\", but he also added, \"Yet we should not pass up our opportunities in that critical 3%.\"\n\n\nFor us not pass up opportunities was more about using the correct data structure and algorithm when and where they make sense.\n\n\nOverall the performances were quite good, on my old personal machine I could get 30k/inserts per second in a very simple table (few numeric value and small texts).\n\n\nThis number is really small compared to Redis that can \nSET\n keys up to 100k/set per second, but we are also doing more work and we have always considered this figures good enough, at least as long as nobody complains.\n\n\nThe complains\n\n\nFortunately\n somebody \ncomplains about the insertion rates\n.\n\n\nHis requirements were a little different from the assumption that we had when testing the performance. He needed to insert a lot of data ~100kB in each row. And to do it fast.\n\n\nFirst tests were not so good, showing just 2000 insertions per second. Definitely not good.\n\n\nLooking for the causes\n\n\nRust, the system language in which RediSQL is built, is peculiar in the management of memory.\n\n\nThe type system must be sure that every reference that you are using is valid and that you will never deference stuff out of your memory space.\n\n\nOf course, this gives you a lot of safety but introduces quite a bit of complexity.\n\n\nFortunately, there are ways to manage this complexity: is possible to trade complexity for performances or, the other way around, performances for complexity.\n\n\nHigh complexity with high performance means that you are using references (pointers) everywhere it is possible, so you never copy memory around if it is not necessary, you pass a pointer to that memory location and the type system assure you that it is safe to deference such pointer.\n\n\nLow complexity with low performance implies to copy areas of memory multiple times so that the type system is always happy. Instead of using a pointer to a piece of memory I will just copy everything I need and pass it around functions.\n\n\nSince the product was new, it made sense for us to get as low complexity as possible in such a way that it is possible to move faster understanding what our clients need and what we want to build.\n\n\nUntil now.\n\n\nThe problem\n\n\nThe biggest problem we identified was that we were copying all the input parameter, so when a client was sending as a request like \nREDISQL.EXEC_STATEMENT DB insert 1 2 3\n we were copying 6 (insert) + 3 (1, 2, 3) = 9 bytes of memory.\n\n\n(Redis string are a little particular since they don't have a null '\\0' terminator and carry along their size.)\n\n\nNobody will complain about copying just ~10 bytes of memory, especially using slab allocator it is still some work but it is quite fast to do.\n\n\nHowever, when we start to ingest 100k bytes this will really impact negatively the performance.\n\n\nNeed for Speed\n\n\nWe could get away with just copying and freeing few bytes, especially using jemalloc, however as soon as the payload start increasing in size copying it every time started to impact negatively the performance of the module.\n\n\nWas time to buy some performances paying our share price in complexity.\n\n\nThe process was a little complex because the data lived outside the Rust code, inside Redis itself.\nIt was necessary to use \nunsafe\n code that in normal Rust you can avoid, but finally, we were able to see the Redis string as a slice (array) of chars and get a reference to it to pass around.\n\n\nResult\n\n\nBefore to release the code I obviously tested it. I used a c4.8xlarge from AWS.\n\n\nThat machine before the patch could ingest 4000 request / second each of ~100k bytes. After the patch, it was able to get 8000 requests/second.\n\n\nFinally, the latency was pretty much the same with the 99.9 percentile at ~50 milliseconds.\n\n\nXin, the gentleman who brought the issues to our attention, went even further setting several parameters available in \nredis-benchmark\n, notably the number of pipelined requests, and he reached 17000 requests per second.\n\n\nBeing conservative we can claim that our works made redisql twice (from 4000 req/s to 8000 req/s) as fast at ingesting big amount of data.\n\n\nIt is definitely necessary more testing to see the impact on different workloads, smaller payload. Fortunately, our preliminary results seem quite good.\n\n\nWrapping up\n\n\nWe showed how was possible to get a lot of performance out of Rust and RediSQL switching to a zero copy approach.\n\n\nWe also showed that our solution is very efficient, being able to ingest 800 MB / s of data without any sort of tuning.\n\n\nLooking for beta tester\n\n\nWe are looking also for tester for the PRO version of RediSQL, if you would like to test the PRO module without paying anything this is your occasion.\nYou can either open an issues on github or write me (siscia) directly (email on github).",
            "title": "Double performances of RediSQL going zero copy"
        },
        {
            "location": "/blog/performances/#doubling-the-performances-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL provides SQL steroids for Redis  RediSQL is a redis module that embeds SQLite to provide full SQL capabilities to redis.  The fastest introduction to RediSQL is  our homepage  tl;dr; We double the performance of RediSQL switching to a zero-copy use of the input arguments.",
            "title": "Doubling the performances of RediSQL, SQL steroids for Redis."
        },
        {
            "location": "/blog/performances/#background",
            "text": "During the development of RediSQL we always kept in mind performance, but only up to a degree.  As Donal Knuth says \"premature optimization is the root of all evil\", but he also added, \"Yet we should not pass up our opportunities in that critical 3%.\"  For us not pass up opportunities was more about using the correct data structure and algorithm when and where they make sense.  Overall the performances were quite good, on my old personal machine I could get 30k/inserts per second in a very simple table (few numeric value and small texts).  This number is really small compared to Redis that can  SET  keys up to 100k/set per second, but we are also doing more work and we have always considered this figures good enough, at least as long as nobody complains.",
            "title": "Background"
        },
        {
            "location": "/blog/performances/#the-complains",
            "text": "Fortunately  somebody  complains about the insertion rates .  His requirements were a little different from the assumption that we had when testing the performance. He needed to insert a lot of data ~100kB in each row. And to do it fast.  First tests were not so good, showing just 2000 insertions per second. Definitely not good.",
            "title": "The complains"
        },
        {
            "location": "/blog/performances/#looking-for-the-causes",
            "text": "Rust, the system language in which RediSQL is built, is peculiar in the management of memory.  The type system must be sure that every reference that you are using is valid and that you will never deference stuff out of your memory space.  Of course, this gives you a lot of safety but introduces quite a bit of complexity.  Fortunately, there are ways to manage this complexity: is possible to trade complexity for performances or, the other way around, performances for complexity.  High complexity with high performance means that you are using references (pointers) everywhere it is possible, so you never copy memory around if it is not necessary, you pass a pointer to that memory location and the type system assure you that it is safe to deference such pointer.  Low complexity with low performance implies to copy areas of memory multiple times so that the type system is always happy. Instead of using a pointer to a piece of memory I will just copy everything I need and pass it around functions.  Since the product was new, it made sense for us to get as low complexity as possible in such a way that it is possible to move faster understanding what our clients need and what we want to build.  Until now.",
            "title": "Looking for the causes"
        },
        {
            "location": "/blog/performances/#the-problem",
            "text": "The biggest problem we identified was that we were copying all the input parameter, so when a client was sending as a request like  REDISQL.EXEC_STATEMENT DB insert 1 2 3  we were copying 6 (insert) + 3 (1, 2, 3) = 9 bytes of memory.  (Redis string are a little particular since they don't have a null '\\0' terminator and carry along their size.)  Nobody will complain about copying just ~10 bytes of memory, especially using slab allocator it is still some work but it is quite fast to do.  However, when we start to ingest 100k bytes this will really impact negatively the performance.",
            "title": "The problem"
        },
        {
            "location": "/blog/performances/#need-for-speed",
            "text": "We could get away with just copying and freeing few bytes, especially using jemalloc, however as soon as the payload start increasing in size copying it every time started to impact negatively the performance of the module.  Was time to buy some performances paying our share price in complexity.  The process was a little complex because the data lived outside the Rust code, inside Redis itself.\nIt was necessary to use  unsafe  code that in normal Rust you can avoid, but finally, we were able to see the Redis string as a slice (array) of chars and get a reference to it to pass around.",
            "title": "Need for Speed"
        },
        {
            "location": "/blog/performances/#result",
            "text": "Before to release the code I obviously tested it. I used a c4.8xlarge from AWS.  That machine before the patch could ingest 4000 request / second each of ~100k bytes. After the patch, it was able to get 8000 requests/second.  Finally, the latency was pretty much the same with the 99.9 percentile at ~50 milliseconds.  Xin, the gentleman who brought the issues to our attention, went even further setting several parameters available in  redis-benchmark , notably the number of pipelined requests, and he reached 17000 requests per second.  Being conservative we can claim that our works made redisql twice (from 4000 req/s to 8000 req/s) as fast at ingesting big amount of data.  It is definitely necessary more testing to see the impact on different workloads, smaller payload. Fortunately, our preliminary results seem quite good.",
            "title": "Result"
        },
        {
            "location": "/blog/performances/#wrapping-up",
            "text": "We showed how was possible to get a lot of performance out of Rust and RediSQL switching to a zero copy approach.  We also showed that our solution is very efficient, being able to ingest 800 MB / s of data without any sort of tuning.",
            "title": "Wrapping up"
        },
        {
            "location": "/blog/performances/#looking-for-beta-tester",
            "text": "We are looking also for tester for the PRO version of RediSQL, if you would like to test the PRO module without paying anything this is your occasion.\nYou can either open an issues on github or write me (siscia) directly (email on github).",
            "title": "Looking for beta tester"
        },
        {
            "location": "/blog/release_0.5.0/",
            "text": "Release 0.5.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr;\n This release does not introduce any new features but it does improve the performances significantly. \nMoreover, we are releasing for multiple platforms, notably for ARMv7 (Rasberry PI), for CentOS7 (Linux AMI on AWS) and of course for Linux generic. \nFinally, we introduce also the TRIAL executable which can be freely downloaded and used, it provides all the functionality of the PRO version but it is limited for evaluation purposes, after ~2 hours it will shut down itself.\n\n\nPerformance Improvement ~20%\n\n\nWe are registering an improvement in performance of roughly 20% with a similar load.\n\n\nOf course, performance inside an SQL database varies a lot depending on the query you are executing.\n\n\nIn our evaluation, we are focusing on a simple query that inserts or updates values in the database.\n\n\nWe decided to focus on \ninsert\ns because is the simplest write operation, hence it cannot be distributed to different instances, and the performance of the single instance will limit the performance of the overall system.\n\n\nHowever, \ninsert\n operations, need to allocate new memory, the allocator used by SQLite is very efficient but we still wanted to see what would happen without the need of allocation, hence we tested also \nupdate\ns\n\n\nWe are seeing an improvement of roughly the 20% in \ninsert\n/\nupsert\n throughput.\n\n\nThe increase in throughput is driven by the switch to a zero-copy architecture.\n\n\nIn Rust, the language in which RediSQL is written is usual to start dealing with lifetime issues simply by copying memory, this, of course, comes with a penalty in performances.\n\n\nHowever, as long as this performance penalty is not an issue is better to just leave as it is and work on the more important parts of the project.\nFor one of our user it was a problem and so we decide to fix it by bringing performance improvements to all. \nMore about this story here.\n\n\nReleases\n\n\nRust produce in general static linked objects, so everything you need is already inside your object and you do not depends on any external library that must be installed in your host system.\n\n\nThis has several advantages, as long as the architecture of your host is the correct one your executable will most likely run.\n\n\nThere is an exception to that, \nlibc\n given its ubiquity and size is compiled dynamically, so your object will need it to be present in your host machine. Which usually is not an issue.\n\n\nUnfortunately is some machine \nlibc\n is present in an older version that the one we are expecting, so the module will not be able to run.\n\n\nVery old systems have this issues as well as CentOS 7 and the Linux AMI on AWS.\n\n\nUnfortunately, cross-compile for a different version of glibc is not as simple as it may seem, but we finally manage :)\n\n\nTrial\n\n\nFinally, we decide to provide open access to the PRO version for evaluation purposes.\n\n\nHence we created a third release that is called TRIAL.\n\n\nThe releases are exactly the same as the PRO one, except that it shuts itself down after ~2 hours.\n\n\nIt is supposed to let you test the PRO version before to commit to buy it, still, you have 14 days of money back guarantee if you don't like the product.\n\n\nClearly, the TRIAL version is not supposed to be used in production.\n\n\nEnd\n\n\nAs always you can find all the public releases on the \ngithub page\n, you can openly access the same public release on the \nopen page of our shop\n or you can buy the complete PRO package \nsigning up in the shop\n.\n\n\nRemember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "Release 0.5.0"
        },
        {
            "location": "/blog/release_0.5.0/#release-050-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr;  This release does not introduce any new features but it does improve the performances significantly. \nMoreover, we are releasing for multiple platforms, notably for ARMv7 (Rasberry PI), for CentOS7 (Linux AMI on AWS) and of course for Linux generic. \nFinally, we introduce also the TRIAL executable which can be freely downloaded and used, it provides all the functionality of the PRO version but it is limited for evaluation purposes, after ~2 hours it will shut down itself.",
            "title": "Release 0.5.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.5.0/#performance-improvement-20",
            "text": "We are registering an improvement in performance of roughly 20% with a similar load.  Of course, performance inside an SQL database varies a lot depending on the query you are executing.  In our evaluation, we are focusing on a simple query that inserts or updates values in the database.  We decided to focus on  insert s because is the simplest write operation, hence it cannot be distributed to different instances, and the performance of the single instance will limit the performance of the overall system.  However,  insert  operations, need to allocate new memory, the allocator used by SQLite is very efficient but we still wanted to see what would happen without the need of allocation, hence we tested also  update s  We are seeing an improvement of roughly the 20% in  insert / upsert  throughput.  The increase in throughput is driven by the switch to a zero-copy architecture.  In Rust, the language in which RediSQL is written is usual to start dealing with lifetime issues simply by copying memory, this, of course, comes with a penalty in performances.  However, as long as this performance penalty is not an issue is better to just leave as it is and work on the more important parts of the project.\nFor one of our user it was a problem and so we decide to fix it by bringing performance improvements to all.  More about this story here.",
            "title": "Performance Improvement ~20%"
        },
        {
            "location": "/blog/release_0.5.0/#releases",
            "text": "Rust produce in general static linked objects, so everything you need is already inside your object and you do not depends on any external library that must be installed in your host system.  This has several advantages, as long as the architecture of your host is the correct one your executable will most likely run.  There is an exception to that,  libc  given its ubiquity and size is compiled dynamically, so your object will need it to be present in your host machine. Which usually is not an issue.  Unfortunately is some machine  libc  is present in an older version that the one we are expecting, so the module will not be able to run.  Very old systems have this issues as well as CentOS 7 and the Linux AMI on AWS.  Unfortunately, cross-compile for a different version of glibc is not as simple as it may seem, but we finally manage :)",
            "title": "Releases"
        },
        {
            "location": "/blog/release_0.5.0/#trial",
            "text": "Finally, we decide to provide open access to the PRO version for evaluation purposes.  Hence we created a third release that is called TRIAL.  The releases are exactly the same as the PRO one, except that it shuts itself down after ~2 hours.  It is supposed to let you test the PRO version before to commit to buy it, still, you have 14 days of money back guarantee if you don't like the product.  Clearly, the TRIAL version is not supposed to be used in production.",
            "title": "Trial"
        },
        {
            "location": "/blog/release_0.5.0/#end",
            "text": "As always you can find all the public releases on the  github page , you can openly access the same public release on the  open page of our shop  or you can buy the complete PRO package  signing up in the shop .  Remember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "End"
        },
        {
            "location": "/blog/release_0.6.0/",
            "text": "Release 0.6.0 of RediSQL, SQL steroids for Redis\n\n\nRediSQL, Redis on SQL steroids.\n\n\nRediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.\n\n\nThe fastest introduction to RediSQL is \nour homepage\n\n\ntl;dr\n This release does not introduce new commands, but it provides a SQLite virtual table implementation that allows making SQL queries against Redis Hashes.\nThe release is important because set the foundation to write more complex commands or SQLite functions.\nPossible ideas could be SQLite functions that append to a list or to a stream, these functions could be used inside triggers to generate an event log of all the operation that happened to a particular table.\n\n\nVirtual Table\n\n\nInside RediSQL is now possible to use the virtual table: \nREDISQL_TABLES_BRUTE_HASH\n.\n\n\nThis virtual table allows to only query Redis hashes that follow a common structure.\n\n\nThe understood structure is:\n\n\nHSET $tableName:$id $col1 $val1 $col2 $val2 ... $colN $valN\n\n\n\n\nWhere the \n$col\ns are constant in the hashes and, of course, the \n$val\ns change from row to row.\n\n\nIn order to create a \nREDISQL_TABLES_BRUTE_HASH\n the syntax is the following:\n\n\nCREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH($tableName, $col1, $col2, ..., $colN);\n\n\n\n\nPlease note that the first parameter of the virtual table is not, as we could expect, the first column of the table, but is the name of hashes that we want to use as table, of course without specifying any \n$id\n.\n\n\nAlso note that is pointless to provide a type to the columns since Redis does store only strings inside the hashes, hence you will get only strings from the virtual table as well.\n\n\nWhat you can do to get numbers, integer or floats, is to exploit the \nCAST\n capabilities of SQLite.\n\n\nYou can find examples of this feature in \nthe documentation.\n\n\nLet me make clear that this virtual table does \nnot\n implements updates, inserts or deletes, at the moment you can only query this type of virtual tables.\n\n\nThe implementation of update and inserts and deletes should not pose significant challenges.\n\n\nImportance of this release\n\n\nThis release is extremely important for architectural reasons inside the module itself.\n\n\nIn order to implement the above virtual table was necessary to keep a pointer to an internal structure of Redis that actually allow calling any Redis command from inside a module.\n\n\nIncluding this pointer into the RediSQL structures make possible to call arbitrary Redis commands.\n\n\nThis opens the gate to quite interesting features, as an example, imagine to be able to call \nLPUSH\n or \nXADD\n inside a trigger.\n\n\nThis will allow to log every operation you are doing against your dataset. You could replay them later in a different instance of RediSQL or maybe also against a different database.\n\n\nYou could write all you operation very fast in memory using RediSQL and when you have enough of them write them to disk against PostgreSQL, MySQL or any other database.\n\n\nEnd\n\n\nAs always you can find all the public releases on the \ngithub page\n, you can openly access the same public release on the \nopen page of our shop\n or you can buy the complete PRO package \nsigning up in the shop\n.\n\n\nRemember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "Release 0.6.0"
        },
        {
            "location": "/blog/release_0.6.0/#release-060-of-redisql-sql-steroids-for-redis",
            "text": "RediSQL, Redis on SQL steroids.  RediSQL is a Redis module that provides full SQL capabilities to Redis, it is the simplest and fastest way to get an SQL database up and running, without incurring in difficult operational issues and it can scale quite well with your business.  The fastest introduction to RediSQL is  our homepage  tl;dr  This release does not introduce new commands, but it provides a SQLite virtual table implementation that allows making SQL queries against Redis Hashes.\nThe release is important because set the foundation to write more complex commands or SQLite functions.\nPossible ideas could be SQLite functions that append to a list or to a stream, these functions could be used inside triggers to generate an event log of all the operation that happened to a particular table.",
            "title": "Release 0.6.0 of RediSQL, SQL steroids for Redis"
        },
        {
            "location": "/blog/release_0.6.0/#virtual-table",
            "text": "Inside RediSQL is now possible to use the virtual table:  REDISQL_TABLES_BRUTE_HASH .  This virtual table allows to only query Redis hashes that follow a common structure.  The understood structure is:  HSET $tableName:$id $col1 $val1 $col2 $val2 ... $colN $valN  Where the  $col s are constant in the hashes and, of course, the  $val s change from row to row.  In order to create a  REDISQL_TABLES_BRUTE_HASH  the syntax is the following:  CREATE VIRTUAL TABLE funny_cats USING REDISQL_TABLES_BRUTE_HASH($tableName, $col1, $col2, ..., $colN);  Please note that the first parameter of the virtual table is not, as we could expect, the first column of the table, but is the name of hashes that we want to use as table, of course without specifying any  $id .  Also note that is pointless to provide a type to the columns since Redis does store only strings inside the hashes, hence you will get only strings from the virtual table as well.  What you can do to get numbers, integer or floats, is to exploit the  CAST  capabilities of SQLite.  You can find examples of this feature in  the documentation.  Let me make clear that this virtual table does  not  implements updates, inserts or deletes, at the moment you can only query this type of virtual tables.  The implementation of update and inserts and deletes should not pose significant challenges.",
            "title": "Virtual Table"
        },
        {
            "location": "/blog/release_0.6.0/#importance-of-this-release",
            "text": "This release is extremely important for architectural reasons inside the module itself.  In order to implement the above virtual table was necessary to keep a pointer to an internal structure of Redis that actually allow calling any Redis command from inside a module.  Including this pointer into the RediSQL structures make possible to call arbitrary Redis commands.  This opens the gate to quite interesting features, as an example, imagine to be able to call  LPUSH  or  XADD  inside a trigger.  This will allow to log every operation you are doing against your dataset. You could replay them later in a different instance of RediSQL or maybe also against a different database.  You could write all you operation very fast in memory using RediSQL and when you have enough of them write them to disk against PostgreSQL, MySQL or any other database.",
            "title": "Importance of this release"
        },
        {
            "location": "/blog/release_0.6.0/#end",
            "text": "As always you can find all the public releases on the  github page , you can openly access the same public release on the  open page of our shop  or you can buy the complete PRO package  signing up in the shop .  Remember that signing up for the PRO product also provide you free support from us, the creator of the project, so that we can point you to the right direction and suggest the best use cases for our product.",
            "title": "End"
        }
    ]
}